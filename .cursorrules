# Cursor AI Assistant Rules - Comprehensive Coding Standards

**Version:** 1.0  
**Last Updated:** 2025-10-19  
**Total Sections:** 72  
**Lines:** 4,800+  
**Compliance:** ISO 27001, OWASP Top 10, GDPR, SOC 2, HIPAA, PCI-DSS

---

## TABLE OF CONTENTS

### PART I: FOUNDATIONS (Sections 1-21)
1. [Code Quality & Best Practices](#1-code-quality--best-practices)
2. [Performance & Optimization](#2-performance--optimization)
3. [Security](#3-security)
4. [Testing](#4-testing)
5. [Error Handling & Logging](#5-error-handling--logging)
6. [Code Organization & Architecture](#6-code-organization--architecture)
7. [Documentation](#7-documentation)
8. [Version Control](#8-version-control)
9. [Accessibility](#9-accessibility)
10. [Internationalization & Localization](#10-internationalization--localization)
11. [Professionalism](#11-professionalism)
12. [File & Folder Organization](#12-file--folder-organization)
13. [Dependency Management](#13-dependency-management)
14. [Build & Deployment](#14-build--deployment)
15. [Production Operations & Maintenance](#15-production-operations--maintenance)
16. [Code Review](#16-code-review)
17. [Special Instructions](#17-special-instructions)
18. [Naming Conventions](#18-naming-conventions)
19. [Comments](#19-comments)
20. [Code Formatting](#20-code-formatting)
21. [Database Design & Optimization](#21-database-design--optimization)

### PART II: DATA & BACKEND (Sections 22-26)
22. [NoSQL Databases](#22-nosql-databases)
23. [Firebase Best Practices](#23-firebase-best-practices)
24. [Authentication & Authorization](#24-authentication--authorization)
25. [GraphQL Best Practices](#25-graphql-best-practices)
26. [Microservices & Distributed Systems](#26-microservices--distributed-systems)

### PART III: INFRASTRUCTURE (Sections 27-31)
27. [Data Privacy & Compliance](#27-data-privacy--compliance)
28. [Monitoring & Observability](#28-monitoring--observability)
29. [Cloud Platform Best Practices](#29-cloud-platform-best-practices)
30. [Container & Orchestration](#30-container--orchestration)
31. [Message Queues & Async Processing](#31-message-queues--async-processing)

### PART IV: FRONTEND & WEB (Sections 32-35)
32. [SEO & Web Performance](#32-seo--web-performance)
33. [Progressive Web Apps (PWA)](#33-progressive-web-apps-pwa)
34. [Real-Time Communication](#34-real-time-communication)
35. [Mobile App Specific](#35-mobile-app-specific)

### PART V: QUALITY & PROCESS (Sections 36-43)
36. [Feature Management](#36-feature-management)
37. [Code Quality Metrics](#37-code-quality-metrics)
38. [Refactoring Guidelines](#38-refactoring-guidelines)
39. [Commit Message Standards](#39-commit-message-standards)
40. [Developer Experience](#40-developer-experience)
41. [Backward Compatibility](#41-backward-compatibility)
42. [Legal & Licensing](#42-legal--licensing)
43. [AI-Assisted Development](#43-ai-assisted-development)

### PART VI: API & INTEGRATION (Sections 44-46)
44. [API Gateway & Rate Limiting](#44-api-gateway--rate-limiting)
45. [Caching Strategies](#45-caching-strategies)
46. [Error Monitoring & Crash Reporting](#46-error-monitoring--crash-reporting)

### PART VII: OPERATIONS & SRE (Sections 47-60)
47. [Cost Optimization](#47-cost-optimization)
48. [Disaster Recovery & Business Continuity](#48-disaster-recovery--business-continuity)
49. [Anti-Patterns to Avoid](#49-anti-patterns-to-avoid)
50. [Serverless Best Practices](#50-serverless-best-practices)
51. [Frontend Frameworks Best Practices](#51-frontend-frameworks-best-practices)
52. [Load Testing & Performance Testing](#52-load-testing--performance-testing)
53. [Technical Debt Management](#53-technical-debt-management)
54. [Chaos Engineering & Resilience Testing](#54-chaos-engineering--resilience-testing)
55. [Team Collaboration & Knowledge Sharing](#55-team-collaboration--knowledge-sharing)
56. [Infrastructure Security Hardening](#56-infrastructure-security-hardening)
57. [Metrics, KPIs & Advanced Observability](#57-metrics-kpis--advanced-observability)
58. [Data Engineering & ETL Pipelines](#58-data-engineering--etl-pipelines)
59. [CI/CD Pipeline Best Practices](#59-cicd-pipeline-best-practices)
60. [SRE (Site Reliability Engineering) Practices](#60-sre-site-reliability-engineering-practices)

### PART VIII: ADVANCED TOPICS (Sections 61-71)
61. [Event-Driven Architecture & Event Sourcing](#61-event-driven-architecture--event-sourcing)
62. [Infrastructure as Code (IaC) Detailed](#62-infrastructure-as-code-iac-detailed)
63. [gRPC & Protocol Buffers](#63-grpc--protocol-buffers)
64. [API Contract Testing & Schema Management](#64-api-contract-testing--schema-management)
65. [Service Mesh Patterns](#65-service-mesh-patterns)
66. [Webhooks Best Practices](#66-webhooks-best-practices)
67. [Green Computing & Sustainability](#67-green-computing--sustainability)
68. [Compliance Frameworks Detailed](#68-compliance-frameworks-detailed)
69. [Logging Best Practices (Expanded)](#69-logging-best-practices-expanded)
70. [RESTful API Design Principles (Detailed)](#70-restful-api-design-principles-detailed)
71. [Quick Reference Guide](#71-quick-reference-guide)
72. [Version Changelog](#72-version-changelog)

---

## 1. CODE QUALITY & BEST PRACTICES

**Related Sections:** [6. Code Organization](#6-code-organization--architecture) | [36. Code Quality Metrics](#36-code-quality-metrics) | [37. Refactoring](#37-refactoring-guidelines)

### General Principles
- Follow SOLID principles (Single Responsibility, Open-Closed, Liskov Substitution, Interface Segregation, Dependency Inversion)
- Apply DRY (Don't Repeat Yourself), KISS (Keep It Simple, Stupid), and YAGNI (You Aren't Gonna Need It) principles
- Write clean, readable, and maintainable code
- Use meaningful and descriptive names for variables, functions, classes, and files
- Keep functions small and focused on a single task
- Prefer composition over inheritance
- Use dependency injection for better testability

### Language-Specific Standards

#### Flutter/Dart
- Follow official Dart style guide and effective Dart guidelines
- Use Flutter best practices (StatelessWidget vs StatefulWidget appropriately)
- Implement proper state management (Provider, Riverpod, BLoC, etc.)
- Use const constructors wherever possible for better performance
- Properly dispose of controllers and streams to prevent memory leaks
- Follow material design or cupertino design guidelines
- Use proper widget keys when necessary
- Implement proper error handling with try-catch blocks
- Use async/await for asynchronous operations
- Leverage Flutter DevTools for performance profiling

#### API Development
- Follow RESTful API design principles
- Use appropriate HTTP methods (GET, POST, PUT, PATCH, DELETE)
- Implement proper HTTP status codes
- Use versioning for APIs (e.g., /api/v1/)
- Implement rate limiting and throttling
- Use proper authentication and authorization (JWT, OAuth 2.0)
- Implement CORS properly
- Return consistent error response formats
- Use pagination for large datasets
- Implement proper request validation
- Use OpenAPI/Swagger for API documentation

#### HTML
- Use semantic HTML5 elements (header, nav, main, article, section, aside, footer)
- Follow W3C HTML standards
- Use proper heading hierarchy (h1-h6)
- Include proper meta tags for SEO
- Ensure all images have alt attributes
- Use ARIA labels for accessibility
- Keep markup clean and properly indented
- Validate HTML using W3C validator

#### CSS
- Follow BEM (Block Element Modifier) methodology or similar naming convention
- Use CSS preprocessors (SCSS/SASS) when appropriate
- Implement mobile-first responsive design
- Use CSS Grid and Flexbox for layouts
- Avoid !important unless absolutely necessary
- Use CSS custom properties (variables) for theming
- Minimize use of inline styles
- Use consistent spacing and indentation
- Implement proper vendor prefixes when needed
- Optimize CSS for performance (minimize reflows and repaints)

#### JavaScript/TypeScript
- Use TypeScript over JavaScript for type safety
- Follow Airbnb JavaScript Style Guide or Google JavaScript Style Guide
- Use ES6+ features appropriately
- Implement proper error handling with try-catch
- Use async/await over callbacks and promises chains
- Avoid global variables
- Use strict equality (===) instead of loose equality (==)
- Implement proper memory management (remove event listeners, clear intervals)
- Use modern module system (ES modules)
- Leverage tree-shaking for optimal bundle size

#### Python
- Follow PEP 8 style guide
- Use type hints for better code clarity
- Use virtual environments for dependency isolation
- Follow pythonic conventions
- Use list comprehensions when appropriate
- Implement proper exception handling
- Use context managers (with statement) for resource management
- Write docstrings for all public modules, functions, classes, and methods

#### Java
- Follow Java Code Conventions
- Use appropriate design patterns
- Implement proper exception handling
- Use generics for type safety
- Follow JavaDoc conventions
- Use appropriate access modifiers
- Implement equals() and hashCode() properly when overriding
- Use try-with-resources for resource management

#### C#/.NET
- Follow Microsoft C# Coding Conventions
- Use LINQ when appropriate
- Implement proper async/await patterns
- Use proper exception handling
- Follow naming conventions (PascalCase for public members, camelCase for private)
- Use XML documentation comments
- Implement IDisposable pattern when necessary

#### Go
- Follow Effective Go guidelines
- Use gofmt for code formatting
- Implement proper error handling (don't ignore errors)
- Use goroutines and channels appropriately
- Avoid goroutine leaks
- Use context for cancellation and timeouts
- Follow Go project layout standards
- Use interfaces for abstraction
- Leverage go vet and golint for code quality

#### Rust
- Follow Rust API Guidelines
- Use rustfmt for code formatting
- Understand ownership, borrowing, and lifetimes
- Use Result and Option types properly
- Avoid unsafe code unless necessary
- Use Clippy for linting
- Write comprehensive tests
- Use cargo for dependency management
- Follow naming conventions (snake_case for functions/variables)

#### PHP
- Follow PSR-1, PSR-12 coding standards
- Use PHP 8+ features appropriately
- Follow Laravel best practices if using Laravel
- Use Composer for dependency management
- Implement proper error handling and logging
- Use type declarations and return types
- Follow MVC architecture
- Use dependency injection
- Implement proper validation and sanitization

#### Ruby
- Follow Ruby Style Guide
- Use RuboCop for linting
- Follow Rails conventions if using Rails
- Use Bundler for dependency management
- Write idiomatic Ruby code
- Use proper naming conventions (snake_case)
- Implement proper testing with RSpec or Minitest
- Use symbols appropriately
- Follow DRY principle

#### Kotlin
- Follow Kotlin coding conventions
- Use null safety features
- Leverage coroutines for async operations
- Use data classes when appropriate
- Follow Android best practices if developing for Android
- Use sealed classes for restricted hierarchies
- Implement proper scope functions (let, run, with, apply, also)
- Use extension functions appropriately

#### Swift
- Follow Swift API Design Guidelines
- Use SwiftLint for code quality
- Leverage optionals properly
- Use Swift naming conventions
- Follow iOS/macOS development best practices
- Use protocols and protocol-oriented programming
- Implement proper memory management (avoid retain cycles)
- Use SwiftUI or UIKit appropriately
- Leverage Combine for reactive programming

#### SQL
- Write optimized queries
- Use proper indexing strategies
- Avoid SELECT * in production code
- Use parameterized queries to prevent SQL injection
- Normalize database design appropriately
- Use transactions for data consistency
- Optimize JOIN operations
- Use EXPLAIN to analyze query performance
- Follow database-specific best practices (PostgreSQL, MySQL, SQL Server)

## 2. PERFORMANCE & OPTIMIZATION

**Related Sections:** [51. Load Testing](#51-load-testing--performance-testing) | [46. Cost Optimization](#46-cost-optimization) | [44. Caching](#44-caching-strategies)

- Write efficient algorithms with optimal time and space complexity
- Avoid premature optimization, but be mindful of performance bottlenecks
- Use appropriate data structures for the task
- Implement lazy loading and code splitting
- Optimize database queries (use indexes, avoid N+1 queries)
- Minimize API calls and implement caching strategies
- Optimize images and assets (compression, lazy loading, appropriate formats)
- Use CDN for static assets
- Implement pagination for large datasets
- Avoid memory leaks (proper cleanup of listeners, subscriptions, timers)
- Use production builds for deployment
- Implement debouncing and throttling for frequent operations
- Profile code regularly to identify performance issues
- Minimize bundle size and optimize for faster load times
- Use service workers and PWA features when appropriate

## 3. SECURITY

**Related Sections:** [23. Authentication](#23-authentication--authorization) | [55. Infrastructure Security](#55-infrastructure-security-hardening) | [67. Compliance](#67-compliance-frameworks-detailed)

**Standards:** OWASP Top 10 | NIST Cybersecurity Framework | CIS Benchmarks

### OWASP Top 10 Security Risks (2021)
1. **Broken Access Control**
   - Implement proper authorization checks
   - Use RBAC (Role-Based Access Control)
   - Validate permissions on every request
   - Prevent horizontal and vertical privilege escalation
2. **Cryptographic Failures**
   - Encrypt sensitive data at rest and in transit
   - Use strong encryption algorithms (AES-256, RSA-2048+)
   - Implement proper key management
   - Never use deprecated algorithms (MD5, SHA1 for security)
3. **Injection**
   - Use parameterized queries (prevent SQL injection)
   - Validate and sanitize all user inputs
   - Use ORMs properly
   - Implement input validation on server-side
4. **Insecure Design**
   - Implement threat modeling
   - Use secure design patterns
   - Follow principle of least privilege
   - Design with security from the start
5. **Security Misconfiguration**
   - Remove default accounts and passwords
   - Disable unnecessary features and services
   - Keep frameworks and libraries updated
   - Implement security headers properly
6. **Vulnerable and Outdated Components**
   - Scan dependencies for vulnerabilities (Snyk, OWASP Dependency-Check)
   - Keep all dependencies updated
   - Remove unused dependencies
   - Monitor security advisories (CVE, GitHub Dependabot)
7. **Identification and Authentication Failures**
   - Implement multi-factor authentication (MFA)
   - Use strong password policies
   - Implement account lockout mechanisms
   - Protect against brute force attacks
8. **Software and Data Integrity Failures**
   - Implement code signing
   - Use integrity checks for artifacts
   - Verify software updates and patches
   - Implement CI/CD pipeline security
9. **Security Logging and Monitoring Failures**
   - Log all authentication and authorization events
   - Implement real-time monitoring and alerting
   - Protect log integrity
   - Regular log analysis for anomalies
10. **Server-Side Request Forgery (SSRF)**
    - Validate and sanitize URLs
    - Implement allow lists for external requests
    - Use network segmentation
    - Disable unused URL schemas

### General Security Best Practices
- Validate and sanitize all user inputs
- Implement proper authentication and authorization
- Use HTTPS for all communications
- Store sensitive data securely (encrypt passwords, use environment variables)
- Prevent SQL injection (use parameterized queries, ORMs)
- Prevent XSS (Cross-Site Scripting) attacks
- Prevent CSRF (Cross-Site Request Forgery) attacks
- Implement proper CORS policies
- Use security headers (CSP, X-Frame-Options, X-Content-Type-Options, HSTS)
- Keep dependencies up to date and scan for vulnerabilities
- Implement rate limiting to prevent abuse
- Use principle of least privilege for permissions
- Log security-relevant events
- Never commit secrets or API keys to version control
- Use secure random number generators for sensitive operations
- Implement security testing in CI/CD (SAST, DAST, SCA)
- Conduct regular security audits and penetration testing

## 4. TESTING

**Related Sections:** [51. Load Testing](#51-load-testing--performance-testing) | [52. Technical Debt](#52-technical-debt-management) | [58. CI/CD](#58-cicd-pipeline-best-practices)

**Standards:** IEEE 829 (Software Test Documentation) | ISO/IEC/IEEE 29119 (Software Testing)

- Write unit tests for all critical functionality
- Aim for high code coverage (80%+ where practical)
- Write integration tests for API endpoints
- Implement end-to-end tests for critical user flows
- Use Test-Driven Development (TDD) when appropriate
- Mock external dependencies in tests
- Keep tests independent and isolated
- Use descriptive test names
- Test edge cases and error conditions
- Maintain test code with the same quality as production code
- Use continuous integration to run tests automatically
- Implement contract testing for microservices (Pact, Spring Cloud Contract)
- Use property-based testing for comprehensive coverage
- Implement mutation testing to verify test quality
- Use visual regression testing (Percy, Chromatic, BackstopJS)
- Implement accessibility testing (axe, WAVE, Lighthouse)
- Perform security testing (OWASP ZAP, Burp Suite)
- Use snapshot testing appropriately (don't overuse)
- Implement smoke tests for quick validation
- Test database migrations and rollbacks

## 5. ERROR HANDLING & LOGGING

- Implement comprehensive error handling
- Use try-catch blocks appropriately
- Provide meaningful error messages
- Log errors with sufficient context for debugging
- Implement different log levels (debug, info, warn, error)
- Don't expose sensitive information in error messages
- Handle network errors gracefully
- Implement retry logic for transient failures
- Use proper exception types
- Implement global error handlers where appropriate

## 6. CODE ORGANIZATION & ARCHITECTURE

- Follow clean architecture principles
- Implement proper separation of concerns
- Use appropriate design patterns
- Organize files and folders logically
- Use feature-based or layer-based folder structure
- Keep related code together
- Implement proper dependency management
- Use dependency injection containers when appropriate
- Separate business logic from UI logic
- Create reusable components and utilities
- Follow single responsibility principle for modules and classes

## 7. DOCUMENTATION

- Write clear and concise comments for complex logic
- Document public APIs and interfaces
- Keep README files up to date with setup instructions
- Document architecture decisions
- Use JSDoc, Dartdoc, or similar tools for API documentation
- Include examples in documentation
- Document environment variables and configuration
- Keep changelog updated with meaningful entries
- Document known issues and limitations
- All documents must have a prefix indicating their type
- All documents must include "Last Updated: [YYYY-MM-DD]" in the title or header

## 8. VERSION CONTROL

- Write meaningful commit messages (use conventional commits format)
- Keep commits atomic and focused
- Use feature branches for development
- Follow Git flow or trunk-based development
- Review code before merging (pull requests)
- Keep commit history clean (rebase when appropriate)
- Tag releases appropriately
- Use .gitignore to exclude unnecessary files

## 9. ACCESSIBILITY

- Follow WCAG 2.1 Level AA guidelines
- Ensure keyboard navigation works properly
- Provide proper ARIA labels and roles
- Ensure sufficient color contrast
- Support screen readers
- Provide text alternatives for images and media
- Make forms accessible with proper labels
- Test with accessibility tools
- Ensure responsive design works on all devices

## 10. INTERNATIONALIZATION & LOCALIZATION

### General Principles
- Use i18n libraries for text strings (i18next, react-intl, Flutter Intl)
- Avoid hardcoding text in UI
- Support multiple languages when appropriate
- Use proper date, time, and number formatting
- Support RTL (right-to-left) languages when needed
- Extract all user-facing strings to translation files

### Standards & Formats
- Follow ISO standards (ISO 639 for languages, ISO 3166 for countries)
- Use UTF-8 encoding for all text files
- Follow W3C internationalization guidelines
- Support Unicode properly
- Use locale-specific formatting for dates, numbers, and currency
- Implement ICU (International Components for Unicode) message format

### Implementation Best Practices
- Use locale fallback strategies
- Implement language detection (browser, user preference, geolocation)
- Handle pluralization rules correctly per language
- Support context-specific translations
- Implement translation keys naming conventions
- Use namespaces to organize translations
- Provide translation management tools for non-developers
- Implement translation coverage reporting
- Test with pseudo-localization
- Support dynamic content translation

## 11. PROFESSIONALISM

- NO emojis in code, comments, or project files
- Use professional language in all documentation
- Keep code clean and well-formatted
- Follow consistent coding style across the project
- Use proper grammar and spelling in comments and documentation
- Maintain professional naming conventions
- Keep the codebase organized and tidy

## 12. FILE & FOLDER ORGANIZATION

- Use clear and descriptive folder names
- Organize files by feature or layer
- Keep folder structure shallow when possible
- Use consistent naming conventions for files
- Group related files together
- Separate source code from configuration files
- Keep assets organized in appropriate folders
- Use index files for cleaner imports when appropriate

## 13. DEPENDENCY MANAGEMENT

- Keep dependencies up to date
- Use exact versions or ranges carefully
- Audit dependencies for security vulnerabilities
- Remove unused dependencies
- Document why specific dependencies are used
- Use lock files (package-lock.json, pubspec.lock, etc.)
- Minimize dependency bloat

## 14. BUILD & DEPLOYMENT

**Related Sections:** [58. CI/CD Pipelines](#58-cicd-pipeline-best-practices) | [47. Disaster Recovery](#47-disaster-recovery--business-continuity) | [59. SRE](#59-sre-site-reliability-engineering-practices)

### Deployment Strategies
- **Blue-Green Deployment**: Zero-downtime deployments with instant rollback
- **Canary Deployment**: Gradual rollout to subset of users with monitoring
- **Rolling Updates**: Sequential instance updates with health verification
- **Feature Toggle Deployment**: Deploy dark, activate with flags

### Build Best Practices
- Use environment-specific configurations
- Implement proper CI/CD pipelines
- Automate testing before deployment
- Use environment variables for configuration
- Implement proper error monitoring in production
- Use production-optimized builds
- Implement proper logging and monitoring
- Have rollback strategies in place
- Version all artifacts with semantic versioning
- Sign artifacts for integrity verification
- Scan for vulnerabilities before deployment

### Database Migrations in Deployment
- Use migration tools (Flyway, Liquibase, Alembic, ActiveRecord)
- Test migrations in staging environment first
- Write reversible migrations when possible
- Implement zero-downtime migration strategies
- Version control all migration scripts
- Document schema changes clearly
- Test rollback procedures thoroughly
- Monitor migration performance impact
- Implement migration locking to prevent concurrent runs
- Backup database before migrations
- Validate data integrity after migrations

### Deployment Verification
- Implement health check endpoints
- Run smoke tests post-deployment
- Verify critical user flows
- Check monitoring and alerting
- Validate configuration changes
- Test rollback capability
- Monitor error rates during deployment
- Verify database connections
- Check external service integrations
- Validate feature flags are correct

## 15. PRODUCTION OPERATIONS & MAINTENANCE

**Related Sections:** [59. SRE Practices](#59-sre-site-reliability-engineering-practices) | [47. Disaster Recovery](#47-disaster-recovery--business-continuity) | [27. Monitoring](#27-monitoring--observability)

### Production Deployment Checklist
- [x] All tests passing (unit, integration, e2e, security)
- [x] Code review approved by at least 2 reviewers
- [x] Security vulnerabilities scanned and resolved
- [x] Performance baselines established and validated
- [x] Database migrations tested and documented
- [x] Feature flags configured correctly
- [x] Monitoring dashboards created
- [x] Alerts and thresholds configured
- [x] Runbooks updated with new features
- [x] On-call rotation assigned
- [x] Rollback plan documented and tested
- [x] Communication plan ready
- [x] Stakeholders notified
- [x] Deployment window scheduled (avoid Fridays unless critical)

### Production Readiness Criteria
- All automated tests passing with >80% coverage
- No critical or high severity security vulnerabilities
- Performance metrics within SLO targets
- Complete documentation (API docs, runbooks, ADRs)
- Monitoring dashboards operational
- Alerts configured with proper thresholds
- On-call team trained and assigned
- Disaster recovery procedures tested
- Capacity planning validated
- Cost estimates reviewed and approved
- Compliance requirements verified
- Security review completed
- Load testing performed successfully
- Chaos testing passed (if applicable)

### Production Environment Management
- Implement strict access controls (MFA, RBAC, audit logging)
- Use bastion hosts or VPN for production access
- Never edit code directly in production
- All changes through CI/CD pipeline only
- Implement change approval workflow
- Use infrastructure as code for consistency
- Monitor and alert on manual changes
- Regular security audits and reviews
- Automated vulnerability scanning
- Patch management process

### Health Checks & Monitoring
- Implement `/health` endpoint for basic health
- Implement `/ready` endpoint for readiness
- Monitor critical dependencies (database, cache, external APIs)
- Track resource utilization (CPU, memory, disk, network)
- Monitor application metrics (request rate, error rate, latency)
- Set up synthetic monitoring for critical paths
- Implement real user monitoring (RUM)
- Monitor business metrics alongside technical metrics
- Create role-specific dashboards
- Alert on SLO violations

### Database Maintenance
- Schedule regular backups (automated, tested)
- Implement backup verification and restoration tests
- Monitor database performance (slow queries, connection pool)
- Optimize indexes based on query patterns
- Archive old data according to retention policy
- Monitor database size and growth trends
- Implement read replicas for scaling
- Regular vacuum/analyze operations (PostgreSQL)
- Monitor replication lag
- Review and optimize table statistics

### Certificate & Secret Management
- Track certificate expiration dates
- Automate certificate renewal (Let's Encrypt, ACM)
- Alert 30 days before certificate expiration
- Implement secrets rotation schedule
- Use secrets management systems (Vault, AWS Secrets Manager)
- Audit secrets access regularly
- Remove unused secrets and certificates
- Document all certificates and their purposes
- Test certificate renewal process
- Implement emergency revocation procedures

### Log Management & Retention
- Implement centralized logging (ELK, Splunk, CloudWatch)
- Set appropriate log levels per environment
- Implement log retention policies (30-90 days production)
- Archive compliance logs for required periods
- Monitor log storage costs
- Implement log sampling for high-volume systems
- Regular log analysis for anomaly detection
- Secure log access with proper RBAC
- Implement log backup and disaster recovery

### Dependency & Security Updates
- Subscribe to security advisories (CVE, vendor notifications)
- Patch critical vulnerabilities within 24-48 hours
- Test security patches in staging before production
- Schedule regular dependency updates (weekly/monthly)
- Monitor dependencies for vulnerabilities (Snyk, Dependabot)
- Implement automated security scanning in CI/CD
- Track patch compliance across all systems
- Document patching procedures and rollback plans
- Maintain security update calendar

### Performance Optimization
- Regular performance profiling and analysis
- Monitor and optimize slow database queries
- Implement caching where appropriate
- Optimize API response times
- Reduce bundle sizes for frontend
- Optimize image and asset delivery
- Monitor and fix memory leaks
- Optimize network calls and payloads
- Review and optimize resource allocation
- Conduct quarterly performance reviews

### Configuration Management
- Use environment variables for all configurations
- Implement configuration validation on startup
- Version control configuration files
- Document all configuration parameters
- Use feature flags for feature activation
- Implement configuration change tracking
- Test configuration changes in staging
- Implement configuration rollback capability
- Audit configuration access
- Use secrets management for sensitive configs

### Incident Response Procedures
- Maintain updated incident response runbooks
- Define clear escalation paths (P0-P4 severity)
- Implement incident communication channels
- Document incident timeline and actions
- Conduct blameless post-mortems
- Create action items with owners and deadlines
- Share incident learnings organization-wide
- Update runbooks based on incidents
- Track MTTR (Mean Time To Recovery)
- Implement incident review process

### Capacity Planning & Scaling
- Monitor resource utilization trends
- Forecast capacity needs 3-12 months ahead
- Implement auto-scaling based on metrics
- Plan for peak loads (seasonal, campaigns)
- Load test before capacity increases
- Document scaling procedures
- Monitor costs during scaling
- Review capacity quarterly
- Plan for organic growth
- Test scaling up and down

### Compliance & Audit Requirements
- Maintain audit logs for all critical actions
- Implement immutable audit trail
- Regular compliance reviews (quarterly)
- Prepare for external audits
- Maintain compliance documentation
- Implement automated compliance checking
- Track compliance metrics and KPIs
- Document all security controls
- Conduct internal security audits
- Review and update policies annually

## 16. CODE REVIEW

- Review all code before merging
- Check for code quality, performance, and security issues
- Ensure tests are included and passing
- Verify documentation is updated
- Check for code style consistency
- Look for potential bugs and edge cases

## 17. SPECIAL INSTRUCTIONS

**Critical Rules - ALWAYS & NEVER:**

- DO NOT generate reports, summaries, or documentation unless explicitly requested
- DO NOT create unnecessary files
- DO NOT add emojis to any project files
- ALWAYS use internationally recognized coding standards
- ALWAYS optimize for performance and efficiency
- ALWAYS maintain professional code quality
- ALWAYS keep file and folder organization clean and logical
- When implementing features, implement them completely and correctly the first time
- Prefer editing existing files over creating new ones unless new files are necessary
- Use the most appropriate and modern approaches for the technology stack being used
- ALWAYS implement observability from day one (logging, metrics, tracing)
- ALWAYS consider failure scenarios and implement graceful degradation
- ALWAYS write tests before marking features as done
- NEVER deploy to production on Fridays (unless critical hotfix)
- ALWAYS use feature flags for risky changes
- ALWAYS review and address technical debt regularly
- ALWAYS implement proper database transaction management
- ALWAYS validate inputs at API boundaries  
- ALWAYS use parameterized queries to prevent SQL injection
- ALWAYS implement rate limiting for public APIs
- ALWAYS encrypt sensitive data at rest and in transit
- NEVER trust client-side validation alone
- NEVER log sensitive information (passwords, tokens, PII)
- NEVER use string concatenation for SQL queries

## 18. NAMING CONVENTIONS

### Files
- Use descriptive names that reflect the file's purpose
- Follow language-specific conventions (camelCase, snake_case, PascalCase, kebab-case)
- Use appropriate file extensions
- For documents: use prefix to indicate type (DOC_, GUIDE_, SPEC_, etc.)

### Variables & Functions
- Use descriptive names that explain purpose
- Avoid single-letter variables (except in loops or mathematical contexts)
- Use camelCase for variables and functions in JavaScript/TypeScript/Java/C#
- Use snake_case for variables and functions in Python
- Use PascalCase for classes and components
- Use UPPER_SNAKE_CASE for constants

### Classes & Components
- Use PascalCase for class names
- Use descriptive names that indicate responsibility
- Suffix with type when appropriate (UserController, AuthService, etc.)

## 19. COMMENTS

- Write comments to explain WHY, not WHAT (code should be self-explanatory)
- Keep comments up to date with code changes
- Remove commented-out code before committing
- Use TODO comments with assignee and date when needed
- Write professional, grammatically correct comments
- Use proper comment syntax for the language
- Document complex algorithms and business logic

## 20. CODE FORMATTING

**Standards:** EditorConfig | Prettier | ESLint | StyleLint

- Use consistent indentation (2 or 4 spaces, never tabs unless language-specific)
- Use a formatter (Prettier, Black, dartfmt, etc.)
- Keep line length reasonable (80-120 characters)
- Use consistent spacing around operators
- Group related code together
- Use blank lines to separate logical sections
- Follow language-specific formatting guidelines

## 21. DATABASE DESIGN & OPTIMIZATION

**Related Sections:** [22. NoSQL Databases](#22-nosql-databases) | [57. Data Engineering](#57-data-engineering--etl-pipelines) | [15. Production Ops](#15-production-operations--maintenance)

- Follow database normalization principles (1NF, 2NF, 3NF)
- Use appropriate data types for columns
- Implement proper indexing strategies (B-tree, hash, composite indexes)
- Design efficient schema with foreign keys and constraints
- Use database migrations for version control
- Implement connection pooling for better performance
- Use transactions appropriately (ACID principles)
- Optimize queries (avoid N+1 queries, use EXPLAIN ANALYZE)
- Implement proper backup and recovery strategies
- Use database-specific features when beneficial (materialized views, partitioning)
- Monitor slow queries and optimize them
- Use read replicas for scaling read operations
- Implement proper archiving strategies for old data
- Use stored procedures and functions judiciously
- Consider denormalization when performance requires it
- Implement database connection pool sizing appropriately
- Set proper connection pool timeouts
- Implement database query timeouts to prevent long-running queries
- Use database read/write splitting for better performance
- Implement database sharding strategies when needed
- Monitor database locks and deadlocks
- Use database connection health checks
- Implement graceful degradation when database is unavailable

## 22. NOSQL DATABASES

**Related Sections:** [21. Database Design](#21-database-design--optimization) | [23. Firebase](#23-firebase-best-practices) | [58. Data Engineering](#58-data-engineering--etl-pipelines)

### General NoSQL Principles
- Choose appropriate NoSQL type (Document, Key-Value, Column-family, Graph)
- Understand CAP theorem tradeoffs (Consistency, Availability, Partition tolerance)
- Design schema based on query patterns, not data structure
- Denormalize data when appropriate for performance
- Implement proper indexing strategies
- Use appropriate consistency levels
- Plan for horizontal scaling from the start
- Implement proper backup and disaster recovery

### MongoDB Best Practices
- Use appropriate schema design patterns (embedded vs referenced documents)
- Create indexes for frequently queried fields
- Use aggregation pipeline for complex queries
- Implement proper connection pooling
- Use projection to limit returned fields
- Avoid large documents (16MB limit)
- Use bulk operations for multiple inserts/updates
- Implement proper error handling
- Use transactions when needed (replica sets)
- Monitor slow queries and optimize
- Use appropriate read/write concerns
- Implement data validation with JSON Schema

### Redis Best Practices
- Use appropriate data structures (Strings, Hashes, Lists, Sets, Sorted Sets)
- Implement key naming conventions (use colons for namespacing)
- Set TTL (Time To Live) for cache entries
- Use pipelining for multiple commands
- Implement pub/sub for real-time messaging
- Use Redis transactions (MULTI/EXEC) when needed
- Monitor memory usage and implement eviction policies
- Use Redis Cluster for horizontal scaling
- Implement proper persistence (RDB, AOF)
- Use Lua scripts for atomic operations
- Avoid large keys and values
- Implement connection pooling

### DynamoDB Best Practices
- Design partition keys for even distribution
- Use composite sort keys for query flexibility
- Implement GSI (Global Secondary Indexes) strategically
- Use LSI (Local Secondary Indexes) sparingly
- Implement pagination with LastEvaluatedKey
- Use batch operations for efficiency
- Implement conditional writes for data integrity
- Use DynamoDB Streams for change tracking
- Optimize for read/write capacity units
- Use on-demand pricing for unpredictable workloads
- Implement proper error handling and retries
- Use DAX (DynamoDB Accelerator) for caching

### Cassandra Best Practices
- Design partition keys to distribute data evenly
- Understand replication factor and consistency levels
- Avoid hotspots in data distribution
- Use appropriate compaction strategies
- Design tables for specific queries (query-first approach)
- Use batching for multiple writes to same partition
- Implement proper tombstone handling
- Monitor cluster health and performance
- Use appropriate data types
- Implement time-series data patterns when needed

### Elasticsearch Best Practices
- Design proper index mapping and analyzers
- Use appropriate shard count and replica settings
- Implement index lifecycle management (ILM)
- Use bulk API for multiple documents
- Optimize search queries with filters and caching
- Implement proper aggregations for analytics
- Use aliases for zero-downtime index updates
- Monitor cluster health and performance
- Implement proper security (authentication, authorization)
- Use appropriate refresh intervals
- Optimize for search vs indexing performance

## 23. FIREBASE BEST PRACTICES

**Related Sections:** [22. NoSQL Databases](#22-nosql-databases) | [24. Authentication](#24-authentication--authorization) | [46. Cost Optimization](#46-cost-optimization)

### Firebase Authentication
- Implement multiple authentication methods (Email, Google, Facebook, Phone)
- Use Firebase Authentication with custom backend tokens
- Implement proper session management
- Use security rules to restrict access
- Implement email verification flows
- Use multi-factor authentication (MFA) for sensitive operations
- Handle authentication state changes properly
- Implement account linking for multiple providers
- Use custom claims for role-based access control
- Implement proper error handling for auth failures

### Firestore (Cloud Firestore)
- Design collections and documents efficiently
- Keep documents small (max 1MB)
- Use subcollections for hierarchical data
- Implement compound indexes for complex queries
- Use security rules to protect data
- Implement proper pagination with query cursors
- Use batch writes for multiple operations
- Implement offline persistence properly
- Use transactions for atomic operations
- Avoid array-contains queries on large arrays
- Use collection group queries when appropriate
- Implement proper listeners cleanup to avoid memory leaks
- Use field transforms (serverTimestamp, increment, arrayUnion)
- Design for scalability (avoid document write contention)

### Realtime Database
- Structure data as flat as possible (avoid deep nesting)
- Implement proper security rules
- Use indexing for query performance
- Implement pagination with limitToFirst/limitToLast
- Use transactions for concurrent writes
- Implement proper listener cleanup
- Use push() for generating unique IDs
- Design for offline functionality
- Implement presence system for online/offline status
- Use Firebase Admin SDK for server-side operations
- Monitor database usage and optimize
- Use appropriate read/write rules

### Cloud Storage for Firebase
- Organize files in logical folder structure
- Use appropriate file naming conventions
- Implement security rules for file access
- Use resumable uploads for large files
- Implement proper error handling
- Generate download URLs with expiration
- Use Firebase Admin SDK for server-side operations
- Implement file metadata for better organization
- Monitor storage usage and costs
- Use appropriate storage locations
- Implement proper file validation (size, type)
- Use Cloud Functions for file processing

### Cloud Functions for Firebase
- Keep functions small and focused
- Use appropriate runtime and memory settings
- Implement proper error handling and logging
- Use async/await for asynchronous operations
- Implement proper timeout handling
- Use environment variables for configuration
- Implement proper security and authentication
- Use onCreate, onUpdate, onDelete triggers appropriately
- Optimize cold start times
- Implement proper cleanup in background functions
- Use callable functions for client-SDK calls
- Monitor function execution and costs
- Implement retry logic for critical operations

### Firebase Cloud Messaging (FCM)
- Implement proper token management
- Use topics for broadcasting messages
- Implement notification and data payloads properly
- Handle messages in foreground and background
- Implement proper error handling
- Use message priority appropriately
- Implement notification channels (Android)
- Use conditional messaging for targeted delivery
- Monitor delivery rates and errors
- Implement proper token refresh logic

### Firebase Performance Monitoring
- Monitor app startup time
- Track network request performance
- Create custom traces for critical operations
- Monitor screen rendering performance
- Set custom attributes for better analysis
- Use Performance Monitoring SDK properly
- Analyze performance data regularly
- Set performance budgets and alerts

### Firebase Analytics
- Implement proper event tracking
- Use standard event names when possible
- Set user properties for segmentation
- Implement e-commerce tracking
- Use audience building for targeting
- Integrate with Google Analytics 4
- Monitor conversion funnels
- Implement proper consent management
- Avoid PII in event parameters

### Firebase Hosting
- Use Firebase Hosting for static content
- Implement proper cache headers
- Use custom domains with SSL
- Implement redirects and rewrites
- Use Firebase Hosting with Cloud Functions (dynamic content)
- Implement proper 404 pages
- Use preview channels for testing
- Monitor hosting usage and performance

### General Firebase Best Practices
- Implement proper error handling across all services
- Monitor costs and set budget alerts
- Use Firebase Extensions for common functionality
- Implement proper security rules for all services
- Use Firebase Admin SDK for backend operations
- Test security rules thoroughly
- Use Firebase Local Emulator Suite for development
- Implement proper data backup strategies
- Monitor quota limits and plan for scaling
- Keep Firebase SDK versions updated
- Use Firebase Remote Config for feature flags
- Implement proper logging and monitoring

## 24. AUTHENTICATION & AUTHORIZATION

**Related Sections:** [3. Security](#3-security) | [23. Firebase Auth](#23-firebase-best-practices) | [55. Infrastructure Security](#55-infrastructure-security-hardening)

**Standards:** OAuth 2.0 RFC 6749 | OpenID Connect | SAML 2.0 | JWT RFC 7519

### General Authentication Principles
- Never store passwords in plain text
- Use strong password hashing algorithms (bcrypt, Argon2, PBKDF2)
- Implement proper password policies (length, complexity)
- Use HTTPS for all authentication requests
- Implement account lockout after failed attempts
- Use secure session management
- Implement proper logout functionality
- Use CSRF tokens for form submissions
- Implement proper error messages (avoid revealing account existence)
- Use secure cookie attributes (HttpOnly, Secure, SameSite)

### JWT (JSON Web Tokens) Best Practices
- Use strong secret keys or asymmetric keys (RS256)
- Set appropriate expiration times (short-lived access tokens)
- Implement refresh token rotation
- Store tokens securely (never in localStorage for sensitive apps)
- Validate all token claims (iss, aud, exp, nbf)
- Use appropriate signing algorithms
- Implement token revocation mechanisms
- Include minimal necessary claims
- Use different tokens for different purposes
- Implement proper error handling for expired/invalid tokens

### OAuth 2.0 Best Practices
- Use authorization code flow with PKCE for public clients
- Implement proper redirect URI validation
- Use state parameter to prevent CSRF
- Validate all OAuth responses
- Implement proper scope management
- Use separate access and refresh tokens
- Implement token refresh logic
- Store tokens securely
- Follow OAuth 2.0 security best current practices
- Use OpenID Connect for authentication

### Multi-Factor Authentication (MFA)
- Support multiple MFA methods (TOTP, SMS, email, hardware keys)
- Implement backup codes for account recovery
- Use time-based one-time passwords (TOTP) as primary MFA
- Avoid SMS as sole MFA method (SIM swap attacks)
- Implement proper MFA enrollment flows
- Allow users to manage their MFA devices
- Implement MFA for sensitive operations
- Use WebAuthn for passwordless authentication
- Implement proper error handling for MFA failures

### Session Management
- Generate cryptographically secure session IDs
- Implement proper session timeout (idle and absolute)
- Regenerate session ID after login
- Implement concurrent session limits
- Store minimal data in sessions
- Use server-side session storage
- Implement proper session cleanup
- Use secure session cookies
- Implement "remember me" functionality securely
- Monitor and log suspicious session activity

### Role-Based Access Control (RBAC)
- Define clear roles and permissions
- Implement principle of least privilege
- Use hierarchical roles when appropriate
- Separate authentication from authorization
- Implement proper permission checking at all levels
- Use centralized authorization logic
- Implement attribute-based access control (ABAC) for complex scenarios
- Cache permissions appropriately
- Audit and log authorization decisions
- Implement proper error handling for unauthorized access

### API Authentication
- Use API keys for service-to-service authentication
- Implement API key rotation
- Use rate limiting per API key
- Implement proper API key storage and management
- Use OAuth 2.0 for third-party API access
- Implement proper CORS configuration
- Use webhook signatures for event verification
- Implement IP whitelisting when appropriate
- Monitor API key usage and anomalies
- Implement proper API key revocation

### Social Authentication (OAuth Providers)
- Support multiple social login providers
- Implement proper OAuth flow for each provider
- Handle account linking properly
- Validate provider tokens on backend
- Store minimal data from social providers
- Implement fallback for provider outages
- Handle account conflicts properly
- Implement proper consent screens
- Monitor provider API changes
- Implement account merging strategies

### Biometric Authentication
- Use platform APIs (Face ID, Touch ID, Windows Hello)
- Implement fallback authentication methods
- Store biometric templates securely (use platform keychain)
- Implement proper error handling
- Request biometric authentication for sensitive operations
- Follow platform-specific guidelines
- Implement enrollment and management flows
- Use biometrics as second factor, not sole factor
- Respect user privacy and consent

### Password Reset & Recovery
- Use secure token-based reset links
- Set short expiration times for reset tokens
- Implement rate limiting on reset requests
- Send notifications for password changes
- Require re-authentication for sensitive changes
- Use email verification for password reset
- Implement account recovery questions carefully (or avoid them)
- Log password reset attempts
- Implement CAPTCHA for reset forms
- Clear all sessions on password change

### Security Best Practices
- Implement brute force protection
- Use CAPTCHA for suspicious activity
- Implement account enumeration protection
- Monitor and log authentication events
- Implement anomaly detection (unusual login locations, devices)
- Use device fingerprinting appropriately
- Implement proper audit logging
- Follow OWASP authentication guidelines
- Regularly update authentication libraries
- Conduct security audits and penetration testing
- Implement proper error handling (don't leak information)
- Use security headers (HSTS, CSP, X-Frame-Options)

## 24. GRAPHQL BEST PRACTICES

**Related Sections:** [23. Authentication](#23-authentication--authorization) | [63. API Contract Testing](#63-api-contract-testing--schema-management) | [45. Caching](#45-caching-strategies)

- Design clear and intuitive schema
- Use proper naming conventions for queries, mutations, and types
- Implement DataLoader to solve N+1 query problems
- Use pagination (cursor-based or offset-based) for large datasets
- Implement proper error handling with custom error types
- Use unions and interfaces for polymorphic types
- Implement field-level authorization
- Use query complexity analysis to prevent abuse
- Implement proper caching strategies
- Document schema with descriptions
- Use subscriptions for real-time updates
- Version schema carefully (avoid breaking changes)
- Implement query depth limiting
- Use fragments to reduce query duplication

## 26. MICROSERVICES & DISTRIBUTED SYSTEMS

**Related Sections:** [30. Message Queues](#30-message-queues--async-processing) | [61. Event-Driven Architecture](#61-event-driven-architecture--event-sourcing) | [65. Service Mesh](#65-service-mesh-patterns)

- Define clear service boundaries based on business domains
- Implement proper service discovery mechanisms
- Use API Gateway for routing and aggregation
- Implement circuit breakers for fault tolerance (Hystrix, Resilience4j)
- Use distributed tracing (Jaeger, Zipkin, OpenTelemetry)
- Implement saga patterns for distributed transactions
- Use message queues for async communication
- Implement proper retry mechanisms with exponential backoff
- Use correlation IDs for request tracking
- Implement health checks and readiness probes
- Design for failure (chaos engineering principles)
- Use event-driven architecture where appropriate
- Implement proper service versioning
- Use containerization for consistency
- Implement proper service mesh (Istio, Linkerd) when needed
- Monitor inter-service communication
- Implement proper timeout strategies
- Use idempotency for operations

## 27. DATA PRIVACY & COMPLIANCE

**Related Sections:** [3. Security](#3-security) | [67. Compliance Frameworks](#67-compliance-frameworks-detailed) | [24. Authentication](#24-authentication--authorization)

- Implement GDPR compliance (right to be forgotten, data portability)
- Follow CCPA regulations for California users
- Implement data encryption at rest and in transit
- Use proper PII (Personally Identifiable Information) handling
- Implement data retention and deletion policies
- Provide clear privacy policies and terms of service
- Implement cookie consent mechanisms
- Use data minimization principles
- Implement proper audit logging for data access
- Provide user data export functionality
- Implement proper consent management
- Use data anonymization and pseudonymization techniques
- Follow privacy by design principles
- Implement proper data breach notification procedures
- Use secure data transfer protocols
- Implement geographic data restrictions when required
- Follow industry-specific compliance (HIPAA, PCI-DSS, SOC 2)

## 28. MONITORING & OBSERVABILITY

**Related Sections:** [57. Metrics & KPIs](#57-metrics-kpis--advanced-observability) | [69. Logging](#69-logging-best-practices-expanded) | [46. Error Monitoring](#46-error-monitoring--crash-reporting)

- Implement Application Performance Monitoring (APM) tools
- Use structured logging (JSON format)
- Implement distributed tracing
- Collect meaningful metrics (RED: Rate, Errors, Duration)
- Use log aggregation tools (ELK stack, Splunk, CloudWatch)
- Implement real-time alerting for critical issues
- Create comprehensive dashboards
- Monitor infrastructure metrics (CPU, memory, disk, network)
- Implement health check endpoints
- Use SLIs (Service Level Indicators) and SLOs (Service Level Objectives)
- Monitor business metrics alongside technical metrics
- Implement proper log retention policies
- Use sampling for high-volume tracing
- Create runbooks for common issues
- Implement anomaly detection
- Monitor third-party dependencies
- Use synthetic monitoring for critical paths
- Implement proper incident management procedures

## 29. CLOUD PLATFORM BEST PRACTICES

**Related Sections:** [62. Infrastructure as Code](#62-infrastructure-as-code-iac-detailed) | [50. Serverless](#50-serverless-best-practices) | [47. Cost Optimization](#47-cost-optimization)

### General Cloud Principles
- Use Infrastructure as Code (Terraform, CloudFormation, Pulumi)
- Implement auto-scaling based on metrics
- Use managed services when appropriate
- Implement multi-region deployment for high availability
- Use cloud-native patterns
- Optimize costs (reserved instances, spot instances)
- Implement proper tagging strategies
- Use cloud provider best practices (AWS Well-Architected, Azure Well-Architected)

### AWS Specific
- Use IAM roles instead of access keys
- Implement least privilege access
- Use VPC for network isolation
- Leverage AWS Lambda for serverless
- Use S3 for object storage with proper lifecycle policies
- Implement CloudWatch for monitoring

### Azure Specific
- Use Azure Active Directory for authentication
- Implement Azure Resource Manager templates
- Use Azure Functions for serverless
- Leverage Azure Monitor

### GCP Specific
- Use Cloud IAM for access control
- Implement Cloud Deployment Manager
- Use Cloud Functions for serverless
- Leverage Stackdriver for monitoring

## 30. CONTAINER & ORCHESTRATION

### Docker Best Practices
- Use official base images
- Minimize image layers
- Use multi-stage builds
- Don't run containers as root
- Use .dockerignore to exclude unnecessary files
- Scan images for vulnerabilities
- Use specific image tags (avoid 'latest')
- Implement health checks in Dockerfiles
- Keep images small
- Use build cache effectively

### Kubernetes Best Practices
- Use namespaces for isolation
- Implement resource requests and limits
- Use liveness and readiness probes
- Implement proper RBAC (Role-Based Access Control)
- Use ConfigMaps and Secrets for configuration
- Implement pod security policies
- Use Horizontal Pod Autoscaling
- Implement network policies
- Use persistent volumes for stateful applications
- Follow the principle of least privilege
- Use labels and selectors effectively
- Implement proper logging and monitoring
- Use Helm for package management
- Implement GitOps workflows (ArgoCD, Flux)

## 31. MESSAGE QUEUES & ASYNC PROCESSING

- Choose appropriate message broker (RabbitMQ, Kafka, SQS, Redis)
- Implement idempotent message processing
- Use dead letter queues for failed messages
- Implement proper retry mechanisms
- Use message acknowledgments correctly
- Implement message expiration and TTL
- Monitor queue depth and processing lag
- Use proper message serialization (JSON, Protobuf, Avro)
- Implement message ordering when required
- Use topic/exchange patterns appropriately
- Implement circuit breakers for downstream services
- Use message batching for efficiency
- Implement proper error handling and logging
- Use correlation IDs for message tracking
- Implement message deduplication
- Monitor consumer lag
- Use partitioning for scalability (Kafka)
- Implement backpressure handling

## 32. SEO & WEB PERFORMANCE

**Related Sections:** [2. Performance](#2-performance--optimization) | [33. Progressive Web Apps](#33-progressive-web-apps-pwa) | [52. Load Testing](#52-load-testing--performance-testing)

### SEO Best Practices
- Use semantic HTML and proper heading hierarchy
- Implement meta tags (title, description, keywords)
- Use Open Graph tags for social media
- Implement structured data (Schema.org, JSON-LD)
- Create XML sitemap
- Implement robots.txt properly
- Use canonical URLs
- Implement proper URL structure (readable, keyword-rich)
- Optimize images with alt tags
- Implement internal linking strategy
- Use HTTPS
- Ensure mobile-friendliness
- Optimize page load speed
- Implement breadcrumb navigation

### Web Performance
- Optimize Core Web Vitals (LCP, FID, CLS)
- Minimize bundle size (code splitting, tree shaking)
- Use lazy loading for images and components
- Implement browser caching strategies
- Use CDN for static assets
- Minimize HTTP requests
- Compress assets (Gzip, Brotli)
- Optimize images (WebP, AVIF, proper sizing)
- Use resource hints (preload, prefetch, preconnect)
- Minimize render-blocking resources
- Implement critical CSS
- Use HTTP/2 or HTTP/3
- Monitor with Lighthouse and WebPageTest
- Implement performance budgets

## 33. PROGRESSIVE WEB APPS (PWA)

- Implement service workers for offline functionality
- Create comprehensive app manifest (manifest.json)
- Use cache-first strategies for static assets
- Implement network-first strategies for dynamic content
- Provide offline fallback pages
- Implement push notifications
- Use web app install prompts
- Ensure HTTPS for all pages
- Implement proper cache versioning
- Use Background Sync API for offline actions
- Implement app shell architecture
- Test offline functionality thoroughly
- Provide indicators for online/offline status
- Use IndexedDB for client-side storage
- Implement proper update strategies for service workers
- Follow PWA checklist (Google)

## 34. REAL-TIME COMMUNICATION

### WebSocket Best Practices
- Implement proper connection management
- Use heartbeat/ping-pong for connection health
- Implement automatic reconnection with exponential backoff
- Handle connection errors gracefully
- Implement proper authentication and authorization
- Use message queuing for reliability
- Implement rate limiting
- Use binary protocols when appropriate (Protocol Buffers)
- Monitor connection counts and message throughput
- Implement proper error handling
- Use rooms/channels for message routing
- Implement presence tracking
- Handle browser lifecycle events (page visibility)

### Socket.io Specific
- Use namespaces for logical separation
- Implement rooms for group communication
- Use acknowledgments for important messages
- Implement proper middleware for authentication

### Server-Sent Events (SSE)
- Use for one-way server-to-client communication
- Implement proper event types
- Handle reconnection automatically
- Implement proper CORS headers

## 35. MOBILE APP SPECIFIC

### Performance
- Optimize battery consumption
- Minimize network requests
- Implement efficient image loading and caching
- Use native components when possible
- Optimize app startup time
- Reduce app size (remove unused resources)
- Implement lazy loading for screens
- Optimize animations (60 FPS target)

### Best Practices
- Handle different screen sizes and orientations
- Implement proper deep linking
- Use platform-specific UI guidelines (Material Design, Human Interface Guidelines)
- Implement proper push notification handling
- Handle background tasks efficiently
- Implement proper error handling and crash reporting
- Use biometric authentication when appropriate
- Implement proper data persistence
- Handle network connectivity changes
- Optimize for different network conditions
- Implement proper app state management
- Follow app store guidelines (Google Play, App Store)
- Implement proper analytics
- Use feature flags for gradual rollouts
- Implement proper security (SSL pinning, secure storage)

## 36. FEATURE MANAGEMENT

- Implement feature flags/toggles for controlled releases
- Use feature flag management tools (LaunchDarkly, Unleash, ConfigCat)
- Implement A/B testing infrastructure
- Use gradual rollouts (canary deployments)
- Implement kill switches for quick feature disabling
- Use user segmentation for targeted features
- Monitor feature usage and performance
- Remove old feature flags after full rollout
- Implement proper feature flag naming conventions
- Use environment-specific feature configurations
- Document feature flag purposes and owners
- Implement feature flag testing in CI/CD
- Use feature flags for trunk-based development
- Monitor technical debt from feature flags
- Implement proper analytics for feature usage

## 37. CODE QUALITY METRICS

- Monitor cyclomatic complexity (keep functions simple)
- Track code coverage (aim for 80%+ on critical paths)
- Measure technical debt regularly
- Use static code analysis tools (SonarQube, CodeClimate)
- Track code smells and refactor regularly
- Monitor duplicate code percentage
- Implement quality gates in CI/CD pipeline
- Track maintainability index
- Monitor cognitive complexity
- Use dependency analysis tools
- Track code churn metrics
- Implement automated code review tools
- Monitor security vulnerabilities
- Track documentation coverage
- Use linting and formatting tools
- Implement pre-commit hooks for quality checks
- Set up dashboards for quality metrics
- Regular code quality reviews

## 38. REFACTORING GUIDELINES

### When to Refactor
- Before adding new features to existing code
- When code becomes difficult to understand
- When you encounter code duplication
- When test coverage is lacking
- During code review feedback
- When performance issues are identified
- When security vulnerabilities are found

### How to Refactor Safely
- Write tests before refactoring (if not present)
- Make small, incremental changes
- Run tests after each change
- Use automated refactoring tools when available
- Keep refactoring commits separate from feature commits
- Use feature flags for large refactorings
- Get code review for significant refactorings
- Document the refactoring rationale

### Common Refactoring Patterns
- Extract method/function
- Rename variables/functions/classes for clarity
- Remove dead code
- Consolidate duplicate code
- Simplify conditional expressions
- Replace magic numbers with named constants
- Break up large classes/functions
- Move code closer to where it's used
- Replace inheritance with composition
- Extract interfaces

### Boy Scout Rule
- Always leave code better than you found it
- Fix small issues when you see them
- Improve naming and comments
- Add missing tests
- Remove unused code

## 39. COMMIT MESSAGE STANDARDS

### Conventional Commits Format
```
<type>(<scope>): <subject>

<body>

<footer>
```

### Types
- **feat**: New feature
- **fix**: Bug fix
- **docs**: Documentation changes
- **style**: Code style changes (formatting, missing semicolons)
- **refactor**: Code refactoring
- **perf**: Performance improvements
- **test**: Adding or updating tests
- **chore**: Maintenance tasks
- **ci**: CI/CD changes
- **build**: Build system changes

### Best Practices
- Use imperative mood ("add" not "added")
- Keep subject line under 50 characters
- Capitalize subject line
- Don't end subject with period
- Separate subject from body with blank line
- Wrap body at 72 characters
- Explain what and why, not how
- Reference issues and pull requests
- Use semantic versioning tags
- Sign commits when required

## 40. DEVELOPER EXPERIENCE

### README Documentation
- Clear project description
- Prerequisites and dependencies
- Installation instructions
- Usage examples
- Configuration options
- API documentation links
- Contributing guidelines
- License information
- Contact information
- Troubleshooting section
- Changelog link

### Contributing Guidelines
- Code of conduct
- How to submit issues
- How to submit pull requests
- Coding standards
- Testing requirements
- Commit message format
- Review process
- Development setup instructions

### Development Environment
- Use Docker for consistent environments
- Provide setup scripts
- Document environment variables
- Use .env.example files
- Provide VS Code/IDE configurations
- Include debugging configurations
- Automate common tasks with scripts/Makefile
- Provide sample data for testing
- Document common issues and solutions

### Developer Tools
- Use linters and formatters
- Configure pre-commit hooks
- Use code snippets and templates
- Provide debugging tools
- Use task runners (Make, npm scripts)
- Implement hot reloading for development
- Use environment-specific configurations
- Provide database seeding scripts

## 41. BACKWARD COMPATIBILITY

- Follow semantic versioning (MAJOR.MINOR.PATCH)
- Maintain deprecated features for at least one major version
- Provide clear deprecation warnings
- Document breaking changes in changelog
- Provide migration guides for major versions
- Use feature flags for gradual transitions
- Support multiple API versions when necessary
- Provide backward-compatible defaults
- Test with older client versions
- Communicate breaking changes well in advance
- Provide automated migration tools when possible
- Use interface versioning strategies
- Implement proper API versioning (URL, header, or content negotiation)
- Maintain compatibility matrices
- Provide rollback strategies

## 42. LEGAL & LICENSING

### Open Source Licensing
- Choose appropriate license (MIT, Apache 2.0, GPL, BSD)
- Include LICENSE file in repository
- Add copyright headers to source files
- Respect third-party licenses
- Maintain NOTICE file for attributions
- Document license compatibility
- Use SPDX identifiers

### Third-Party Dependencies
- Audit licenses of all dependencies
- Ensure license compatibility
- Maintain bill of materials (SBOM)
- Provide attribution for third-party code
- Check for license violations in CI/CD
- Document licensing requirements

### Copyright & Attribution
- Include copyright notices
- Provide proper attribution for borrowed code
- Respect trademark guidelines
- Include required notices in distributions
- Document contributor agreements
- Follow open source contribution policies

## 43. AI-ASSISTED DEVELOPMENT

### Using AI Code Assistants Responsibly
- Review all AI-generated code carefully
- Test AI-generated code thoroughly
- Ensure AI-generated code follows project standards
- Verify licensing compliance of AI suggestions
- Don't blindly accept AI suggestions
- Use AI for boilerplate and repetitive tasks
- Validate AI-generated security code
- Document when AI assistance was used for critical code
- Train team on effective AI tool usage
- Maintain code quality standards regardless of source

### Prompt Engineering for Better Code
- Provide clear context and requirements
- Specify coding standards and conventions
- Request specific patterns or architectures
- Ask for explanations of generated code
- Iterate on AI responses for better results
- Use AI for code review and suggestions
- Leverage AI for documentation generation
- Use AI for test case generation

## 44. API GATEWAY & RATE LIMITING

### API Gateway Patterns
- Implement centralized authentication and authorization
- Use API Gateway for request routing and aggregation
- Implement request/response transformation
- Enable API composition (orchestration and choreography)
- Implement protocol translation (REST to gRPC, etc.)
- Use API Gateway for load balancing
- Implement request validation at gateway level
- Enable response caching at gateway
- Use API Gateway for A/B testing and canary releases
- Implement API versioning strategies

### Rate Limiting Strategies
- Implement token bucket algorithm for smooth rate limiting
- Use leaky bucket for strict rate control
- Implement sliding window for accurate rate limiting
- Use fixed window for simple rate limiting
- Implement rate limiting per user, IP, or API key
- Set different rate limits for different endpoints
- Implement burst handling strategies
- Use distributed rate limiting for scaled systems (Redis)
- Provide clear rate limit headers (X-RateLimit-*)
- Implement exponential backoff for clients
- Use 429 (Too Many Requests) status code appropriately
- Implement graceful degradation when rate limited

### Request Management
- Implement request throttling for resource protection
- Use request queuing for handling traffic spikes
- Implement priority queuing for critical requests
- Set appropriate timeout values
- Implement circuit breakers for failing upstream services
- Use bulkhead pattern to isolate resources
- Implement request deduplication
- Monitor and alert on rate limit violations

## 45. CACHING STRATEGIES

### Cache Patterns
- **Cache-Aside (Lazy Loading)**: Application manages cache explicitly
  - Check cache before database
  - Load from database if cache miss
  - Populate cache after database read
- **Write-Through**: Write to cache and database synchronously
  - Ensure cache and database consistency
  - Higher write latency
- **Write-Behind (Write-Back)**: Write to cache first, database asynchronously
  - Lower write latency
  - Risk of data loss if cache fails
- **Refresh-Ahead**: Proactively refresh cache before expiration
  - Reduce cache miss rate
  - Improve read performance

### Cache Invalidation
- Use Time-To-Live (TTL) for automatic expiration
- Implement cache invalidation on data updates
- Use event-driven cache invalidation
- Implement versioned cache keys
- Use cache tagging for group invalidation
- Implement soft deletion with lazy cleanup
- Monitor stale cache data
- Use cache warming for critical data

### Multi-Level Caching
- **Level 1 - Browser/Client Cache**: Static assets, API responses
- **Level 2 - CDN Cache**: Static content, media files
- **Level 3 - Application Cache**: In-memory cache (Redis, Memcached)
- **Level 4 - Database Cache**: Query cache, buffer pool
- Configure appropriate TTLs for each level
- Implement cache coherence across levels
- Use cache headers properly (Cache-Control, ETag)

### Cache Key Design
- Use consistent key naming conventions
- Include version in cache keys
- Use namespacing to organize keys (user:123:profile)
- Implement hierarchical key structure
- Avoid cache key collisions
- Keep keys short but descriptive
- Use hashing for complex keys

### Best Practices
- Cache frequently accessed, rarely changed data
- Don't cache sensitive data without encryption
- Monitor cache hit/miss ratios
- Set appropriate memory limits
- Implement cache preloading for critical data
- Use compression for large cached values
- Implement cache stampede prevention
- Monitor cache memory usage and eviction rates

## 46. ERROR MONITORING & CRASH REPORTING

### Error Monitoring Tools
- Implement Sentry, Bugsnag, Rollbar, or similar tools
- Configure error tracking for all environments
- Set up source maps for JavaScript/TypeScript debugging
- Implement error fingerprinting for grouping
- Configure alert rules and notifications
- Integrate with issue tracking systems
- Set up performance monitoring
- Monitor real user monitoring (RUM)

### Error Handling & Reporting
- Capture and report unhandled exceptions
- Log contextual information with errors (user ID, request ID, etc.)
- Implement breadcrumb logging for debugging
- Capture user actions leading to errors
- Report network errors and API failures
- Monitor third-party service failures
- Track JavaScript errors in production
- Implement error sampling for high-volume applications

### Alerting & Notifications
- Configure alert thresholds for error rates
- Set up severity-based alerting
- Implement alert grouping and deduplication
- Configure on-call rotations
- Use alert fatigue prevention strategies
- Implement escalation policies
- Send alerts to appropriate channels (Slack, PagerDuty, etc.)
- Monitor alert response times

### Error Analysis
- Group similar errors together
- Track error trends over time
- Identify error patterns and root causes
- Prioritize errors by impact and frequency
- Monitor error resolution rates
- Conduct post-mortem analysis for critical errors
- Track error regression
- Implement error budgets

### User Feedback
- Implement user feedback collection on errors
- Allow users to provide context for errors
- Implement screenshot capture on errors
- Provide error reference IDs to users
- Follow up on user-reported errors
- Analyze user feedback for patterns

### Privacy & Security
- Sanitize sensitive data from error logs
- Don't log passwords or tokens
- Implement PII redaction
- Use secure error reporting channels
- Comply with data retention policies
- Anonymize user data when appropriate

## 47. COST OPTIMIZATION

### Cloud Cost Management
- Monitor cloud spending regularly with detailed dashboards
- Set up budget alerts and thresholds
- Use cost allocation tags for resource tracking
- Implement showback/chargeback for team accountability
- Review and optimize monthly spending
- Use cloud cost management tools (AWS Cost Explorer, Azure Cost Management)
- Implement FinOps practices
- Conduct regular cost review meetings

### Compute Optimization
- Use reserved instances for predictable workloads (save up to 75%)
- Implement spot instances for non-critical workloads
- Use auto-scaling to match demand
- Right-size instances based on actual usage
- Shut down non-production environments during off-hours
- Use serverless for sporadic workloads
- Implement container orchestration for efficient resource usage
- Monitor CPU and memory utilization

### Storage Optimization
- Use appropriate storage tiers (hot, cool, archive)
- Implement data lifecycle policies
- Compress data before storage
- Delete unused snapshots and backups
- Use object storage for static content
- Implement data deduplication
- Archive old logs and data
- Monitor storage growth trends

### Database Optimization
- Right-size database instances
- Use read replicas to scale read operations
- Implement query optimization and indexing
- Use connection pooling
- Archive old data to cheaper storage
- Consider serverless database options
- Monitor database performance metrics
- Use database query caching

### Network Optimization
- Minimize data transfer between regions
- Use CDN to reduce origin requests
- Implement compression for data transfer
- Use private networking when possible
- Optimize API payload sizes
- Implement efficient pagination
- Monitor bandwidth usage
- Use VPC endpoints to avoid data transfer costs

### Resource Management
- Review and remove unused resources regularly
- Delete orphaned resources (unattached volumes, unused IPs)
- Implement resource tagging for tracking
- Use infrastructure as code to prevent resource sprawl
- Automate resource cleanup
- Implement resource quotas and limits
- Monitor resource utilization
- Conduct quarterly resource audits

## 48. DISASTER RECOVERY & BUSINESS CONTINUITY

### Recovery Objectives
- Define RPO (Recovery Point Objective) - maximum acceptable data loss
- Define RTO (Recovery Time Objective) - maximum acceptable downtime
- Document recovery objectives for each system
- Align recovery objectives with business requirements
- Consider cost vs. resilience tradeoffs
- Review and update objectives regularly

### Backup Strategies
- Implement automated backup schedules
- Use 3-2-1 backup rule (3 copies, 2 media types, 1 off-site)
- Configure backup retention policies
- Encrypt backups at rest and in transit
- Test backup integrity regularly
- Implement incremental and full backups
- Store backups in multiple regions
- Monitor backup success/failure
- Document backup procedures

### Restore Procedures
- Test restore procedures regularly (at least quarterly)
- Document step-by-step restore processes
- Measure actual RTO during tests
- Automate restore processes where possible
- Maintain restore runbooks
- Train team on restore procedures
- Conduct surprise restore drills
- Track restore time metrics

### High Availability
- Use multi-region deployment for critical services
- Implement active-active or active-passive failover
- Use load balancers for redundancy
- Implement database replication (synchronous/asynchronous)
- Use auto-scaling for resilience
- Implement health checks and automated failover
- Eliminate single points of failure
- Design for fault tolerance

### Disaster Recovery Planning
- Create comprehensive disaster recovery plan
- Document roles and responsibilities
- Establish communication protocols
- Create incident response procedures
- Maintain contact lists for key personnel
- Document system dependencies
- Create recovery runbooks for each system
- Review and update DR plan regularly

### Testing & Drills
- Conduct disaster recovery drills regularly
- Test different failure scenarios
- Measure actual vs. planned RTO/RPO
- Document lessons learned
- Update procedures based on drill results
- Involve all relevant teams
- Test third-party dependencies
- Conduct tabletop exercises

### Incident Management
- Implement incident response procedures
- Define severity levels and escalation paths
- Maintain incident communication channels
- Document incidents and resolutions
- Conduct post-incident reviews
- Track mean time to recovery (MTTR)
- Implement incident command system
- Use incident management tools

## 49. ANTI-PATTERNS TO AVOID

### Code Anti-Patterns
- **God Object/God Class**: Classes that know or do too much
  - Violates single responsibility principle
  - Difficult to test and maintain
  - Solution: Break into smaller, focused classes
- **Spaghetti Code**: Tangled, complex control flow
  - Difficult to understand and debug
  - Solution: Refactor with clear structure and patterns
- **Copy-Paste Programming**: Duplicating code instead of reusing
  - Violates DRY principle
  - Solution: Extract common code into functions/classes
- **Magic Numbers/Strings**: Unexplained literal values in code
  - Reduces code readability
  - Solution: Use named constants
- **Premature Optimization**: Optimizing before measuring
  - Wastes time on insignificant improvements
  - Solution: Profile first, then optimize bottlenecks
- **Golden Hammer**: Using one solution for all problems
  - "When you have a hammer, everything looks like a nail"
  - Solution: Choose appropriate tools for each problem
- **Cargo Cult Programming**: Using patterns without understanding
  - Solution: Understand why before implementing
- **Lava Flow**: Dead code that nobody dares to remove
  - Solution: Remove unused code confidently with version control

### Architecture Anti-Patterns
- **Big Ball of Mud**: System with no clear architecture
  - Difficult to maintain and extend
  - Solution: Implement clean architecture principles
- **Vendor Lock-in**: Over-dependence on specific vendor
  - Solution: Use abstraction layers, avoid vendor-specific features
- **Distributed Monolith**: Microservices with tight coupling
  - Worst of both monolith and microservices
  - Solution: Ensure proper service boundaries and independence
- **Chatty APIs**: Too many API calls for simple operations
  - Performance and latency issues
  - Solution: Implement proper aggregation, use GraphQL
- **Stovepipe System**: Multiple systems that don't integrate
  - Solution: Implement proper integration patterns

### Database Anti-Patterns
- **Select * Queries**: Retrieving all columns unnecessarily
  - Performance impact
  - Solution: Select only needed columns
- **N+1 Query Problem**: Separate query for each related item
  - Performance killer
  - Solution: Use joins or eager loading
- **Missing Indexes**: Slow queries due to lack of indexes
  - Solution: Add appropriate indexes based on query patterns
- **Over-indexing**: Too many indexes slow down writes
  - Solution: Index strategically, remove unused indexes

### API Anti-Patterns
- **API Versioning in URL Path**: /api/v1/users (debatable)
  - Consider header-based versioning
- **Ignoring HTTP Methods**: Using only GET and POST
  - Solution: Use appropriate HTTP methods (PUT, PATCH, DELETE)
- **Not Using HTTP Status Codes Properly**
  - Solution: Return correct status codes (200, 201, 400, 404, 500, etc.)
- **Exposing Internal Implementation**: Leaking DB structure in API
  - Solution: Use DTOs, hide implementation details

### Security Anti-Patterns
- **Hardcoded Credentials**: Passwords in source code
  - Solution: Use environment variables, secrets management
- **Security by Obscurity**: Relying on secrecy instead of proper security
  - Solution: Implement proper encryption and authentication
- **Insufficient Input Validation**
  - Solution: Validate and sanitize all inputs

## 50. SERVERLESS BEST PRACTICES

### Function Design
- Keep functions small and focused (single responsibility)
- Design functions to be stateless
- Use environment variables for configuration
- Implement proper error handling and retries
- Set appropriate timeout values
- Configure memory allocation based on profiling
- Use layers for shared dependencies
- Implement idempotent functions
- Avoid recursive calls that could cause runaway costs

### Cold Start Optimization
- Minimize package size and dependencies
- Use provisioned concurrency for critical functions
- Keep initialization code outside handler
- Reuse connections and SDK clients
- Use compiled languages for faster cold starts (Go, Rust)
- Implement lazy loading for heavy dependencies
- Warm up functions with scheduled events if needed
- Monitor and optimize cold start metrics

### Security & Access Control
- Follow principle of least privilege for IAM roles
- Use separate roles for each function
- Don't hardcode secrets or credentials
- Use secrets management services (AWS Secrets Manager, etc.)
- Implement proper input validation
- Use VPC for accessing private resources
- Enable encryption at rest and in transit
- Monitor function invocations for anomalies
- Implement API authentication and authorization

### Performance & Scalability
- Set appropriate concurrency limits
- Use asynchronous invocations for non-critical operations
- Implement dead letter queues for failed invocations
- Use streaming for large payloads
- Optimize function memory for cost/performance balance
- Implement circuit breakers for external dependencies
- Use connection pooling for database connections
- Monitor throttling and error rates
- Implement graceful degradation

### Cost Optimization
- Optimize execution time to reduce costs
- Right-size memory allocation
- Use reserved concurrency wisely
- Clean up unused functions and versions
- Implement function lifecycle management
- Monitor costs per function
- Use cost allocation tags
- Consider alternatives for long-running tasks
- Batch operations when possible

### Monitoring & Debugging
- Implement structured logging
- Use distributed tracing (X-Ray, OpenTelemetry)
- Monitor cold starts and execution duration
- Set up CloudWatch alarms for errors
- Implement custom metrics
- Use log aggregation tools
- Enable detailed monitoring
- Implement health checks
- Track business metrics

### Event-Driven Architecture
- Use appropriate event sources (S3, DynamoDB, SQS, etc.)
- Implement event filtering
- Handle duplicate events (idempotency)
- Use batch processing for efficiency
- Implement dead letter queues
- Monitor event processing lag
- Use event sourcing patterns when appropriate
- Implement saga patterns for distributed transactions

## 51. FRONTEND FRAMEWORKS BEST PRACTICES

### React Best Practices
- Use functional components and hooks over class components
- Implement proper component composition
- Use PropTypes or TypeScript for type checking
- Optimize re-renders with React.memo, useMemo, useCallback
- Use React.lazy and Suspense for code splitting
- Implement proper error boundaries
- Follow React naming conventions (PascalCase for components)
- Keep components small and focused
- Use custom hooks for reusable logic
- Implement proper state management (Context API, Redux, Zustand)
- Avoid prop drilling (use context or state management)
- Use keys properly in lists
- Clean up effects with cleanup functions
- Follow React hooks rules (only call at top level)
- Use React DevTools for debugging and profiling

### Vue.js Best Practices
- Use Composition API for better code organization (Vue 3)
- Implement proper component lifecycle management
- Use single-file components (.vue files)
- Follow Vue naming conventions (kebab-case for components in templates)
- Use computed properties for derived state
- Implement proper reactivity patterns
- Use v-for with :key properly
- Avoid mutating props
- Use Vue Router for routing
- Implement Vuex or Pinia for state management
- Use scoped styles in components
- Leverage Vue DevTools for debugging
- Implement proper event handling
- Use slots for component composition

### Angular Best Practices
- Use Angular CLI for project generation and scaffolding
- Follow Angular style guide
- Implement lazy loading for feature modules
- Use reactive forms over template-driven forms
- Implement proper dependency injection
- Use RxJS operators effectively
- Unsubscribe from observables to prevent memory leaks
- Use Angular services for business logic
- Implement proper routing with route guards
- Use Angular modules for code organization
- Implement proper change detection strategies (OnPush)
- Use Angular Material or other UI libraries
- Follow TypeScript best practices
- Use Angular DevTools for debugging

### Svelte Best Practices
- Leverage Svelte's reactive declarations ($:)
- Use stores for global state management
- Implement proper component composition
- Use slots for flexible components
- Leverage Svelte's built-in transitions and animations
- Keep components simple and declarative
- Use SvelteKit for full-stack applications
- Implement proper event forwarding
- Use context API for dependency injection
- Follow Svelte naming conventions

### General Frontend Best Practices
- Implement code splitting for optimal bundle size
- Use tree shaking to eliminate dead code
- Implement proper SEO (meta tags, SSR/SSG when needed)
- Optimize images and assets
- Implement accessibility (WCAG 2.1)
- Use CSS-in-JS or CSS modules for scoped styles
- Implement responsive design (mobile-first)
- Use performance monitoring (Lighthouse, Web Vitals)
- Implement proper error handling and error boundaries
- Use TypeScript for type safety
- Implement proper testing (unit, integration, e2e)
- Follow component-driven development
- Use design systems and component libraries
- Implement proper form validation
- Use modern CSS features (Grid, Flexbox, CSS Variables)

## 52. LOAD TESTING & PERFORMANCE TESTING

### Performance Benchmarks
- Define clear performance SLAs (response time, throughput, error rate)
- Establish performance baselines for all critical endpoints
- Set performance budgets for page load times
- Define acceptable latency thresholds (p50, p95, p99)
- Document performance requirements before implementation

### Load Testing Strategy
- Use appropriate load testing tools (JMeter, k6, Gatling, Locust, Artillery)
- Test under various load conditions (normal, peak, stress, spike)
- Implement soak testing for memory leak detection
- Test API endpoints for response time degradation
- Simulate realistic concurrent user behavior
- Test with production-like data volumes
- Include think time and realistic user flows
- Test from multiple geographic locations

### Performance Testing Types
- **Load Testing**: Normal to peak expected load
- **Stress Testing**: Beyond normal capacity to find breaking point
- **Spike Testing**: Sudden increase/decrease in load
- **Soak Testing**: Sustained load over extended period
- **Scalability Testing**: Validate auto-scaling behavior
- **Endurance Testing**: Long-running tests for stability

### Monitoring During Tests
- Monitor resource utilization (CPU, memory, disk I/O, network)
- Track database performance and connection pools
- Monitor cache hit/miss ratios
- Track error rates and types
- Monitor third-party service response times
- Use APM tools during load tests
- Monitor infrastructure auto-scaling behavior

### Analysis & Optimization
- Identify bottlenecks (application, database, network, external services)
- Analyze slow queries and optimize
- Review and optimize resource allocation
- Implement caching where appropriate
- Optimize database indexes
- Review and fix N+1 query problems
- Optimize API payload sizes
- Implement connection pooling properly

### Continuous Performance Testing
- Integrate performance tests into CI/CD pipeline
- Run performance tests on staging before production
- Implement performance regression detection
- Track performance trends over time
- Alert on performance degradation
- Document performance improvements
- Share performance results with team

## 53. TECHNICAL DEBT MANAGEMENT

### Identifying Technical Debt
- Track technical debt in project backlog
- Categorize debt by type (code, architecture, infrastructure, testing, documentation)
- Use static analysis tools (SonarQube, CodeClimate, Codacy)
- Measure code complexity and maintainability
- Identify deprecated dependencies and technologies
- Document workarounds and temporary solutions
- Track security vulnerabilities as debt

### Debt Assessment
- Assess impact of each debt item (high, medium, low)
- Estimate effort required to address debt
- Calculate interest (ongoing cost of keeping debt)
- Prioritize debt by ROI (return on investment)
- Consider business impact vs. technical impact
- Evaluate risk of not addressing debt
- Document reasons debt was incurred

### Debt Management Strategy
- Allocate 10-20% of sprint capacity for debt reduction
- Create quarterly debt reduction roadmap
- Balance feature development with debt paydown
- Use boy scout rule (leave code better than you found it)
- Address high-impact debt items first
- Set quality gates to prevent new debt
- Review debt regularly in retrospectives

### Preventing New Debt
- Enforce code review standards
- Implement automated quality gates in CI/CD
- Set code coverage thresholds
- Use linting and formatting tools
- Document architecture decisions (ADRs)
- Avoid shortcuts without documenting as debt
- Educate team on quality standards
- Budget time for proper implementation

### Communicating Debt
- Make debt visible to stakeholders
- Explain business impact of debt
- Track debt metrics over time
- Report on debt reduction progress
- Include debt in release notes when relevant
- Celebrate debt reduction achievements
- Share lessons learned

### Debt Reduction Tactics
- Refactor incrementally (strangler fig pattern)
- Use feature flags for gradual migrations
- Write tests before refactoring
- Modernize dependencies systematically
- Consolidate duplicate code
- Improve documentation as you work
- Remove dead code regularly
- Upgrade frameworks and libraries proactively

## 54. CHAOS ENGINEERING & RESILIENCE TESTING

### Chaos Engineering Principles
- Define steady state (normal system behavior)
- Hypothesize steady state will continue during chaos
- Introduce controlled chaos experiments
- Try to disprove hypothesis (find weaknesses)
- Minimize blast radius (start small)
- Run experiments in production (eventually)
- Automate experiments for continuous validation

### Failure Scenarios to Test
- **Service Failures**: Terminate instances, kill processes
- **Network Issues**: Inject latency, packet loss, network partitions
- **Resource Exhaustion**: CPU spike, memory pressure, disk full
- **Dependency Failures**: Third-party API down, database unavailable
- **Infrastructure Failures**: AZ failure, region failure
- **Data Corruption**: Invalid data, missing data
- **Time-based Failures**: Clock skew, timeout issues

### Chaos Testing Tools
- Use Chaos Monkey for random instance termination
- Implement Gremlin for sophisticated failure injection
- Use Litmus for Kubernetes chaos testing
- Leverage AWS Fault Injection Simulator
- Use toxiproxy for network condition simulation
- Implement custom chaos scripts for specific scenarios

### Testing Resilience Patterns
- Validate circuit breaker behavior
- Test fallback mechanisms
- Verify retry logic with exponential backoff
- Test bulkhead isolation
- Validate timeout handling
- Test graceful degradation
- Verify health check accuracy
- Test auto-recovery procedures

### Chaos Experiment Process
1. Define steady state metrics
2. Create hypothesis about resilience
3. Start with staging environment
4. Define blast radius (single service, single region)
5. Run experiment during business hours
6. Monitor system behavior closely
7. Have rollback plan ready
8. Document results and learnings
9. Gradually increase experiment scope
10. Automate successful experiments

### Game Days
- Schedule regular game days (quarterly)
- Simulate realistic disaster scenarios
- Involve entire team (dev, ops, support)
- Test communication protocols
- Validate runbooks and documentation
- Practice incident response procedures
- Test backup and restore processes
- Document lessons learned
- Update procedures based on findings

### Progressive Chaos Testing
- Start in development environment
- Progress to staging/QA
- Begin with off-peak hours in production
- Gradually increase blast radius
- Increase experiment complexity over time
- Build confidence before major experiments
- Always have abort mechanisms

## 55. TEAM COLLABORATION & KNOWLEDGE SHARING

### Code Review Culture
- Review all code before merging (no exceptions)
- Provide constructive, specific feedback
- Review within 24 hours of submission
- Use review checklists for consistency
- Focus on learning, not criticism
- Ask questions to understand intent
- Approve only when you understand the code
- Share knowledge through code reviews
- Use automated tools to catch basic issues
- Review tests along with implementation

### Pair Programming
- Use pair programming for complex features
- Rotate pairs regularly
- Mix experience levels (senior + junior)
- Use driver-navigator pattern
- Take regular breaks
- Switch roles frequently
- Communicate constantly
- Share keyboard time equally
- Document decisions made during pairing
- Use remote pair programming tools when needed

### Knowledge Sharing
- Conduct regular tech talks and demos
- Share interesting problems and solutions
- Document tribal knowledge
- Create and maintain internal wiki
- Record video tutorials for complex topics
- Host lunch-and-learn sessions
- Attend and share conference learnings
- Write internal blog posts
- Create code examples and templates
- Maintain FAQ and troubleshooting guides

### Documentation Practices
- Create architecture decision records (ADRs)
- Maintain up-to-date README files
- Document system architecture diagrams
- Keep API documentation current
- Document deployment procedures
- Create troubleshooting guides
- Maintain runbooks for operations
- Document known issues and workarounds
- Use diagrams (C4, sequence, component)
- Make documentation searchable

### Mob Programming
- Use for particularly complex problems
- Include 3-7 people maximum
- Use timer for rotation (10-15 minutes)
- One driver, rest are navigators
- Encourage all participants to contribute
- Take breaks every 90 minutes
- Document decisions in real-time
- Use for knowledge transfer
- Rotate facilitator role

### On-Call & Incident Response
- Establish clear on-call rotation
- Create and maintain runbooks
- Document escalation procedures
- Provide on-call compensation/time off
- Conduct blameless post-mortems
- Share incident learnings widely
- Update runbooks after incidents
- Provide on-call training
- Use incident management tools
- Track MTTR and improve over time

### Mentorship & Growth
- Pair junior developers with mentors
- Set clear learning objectives
- Provide regular feedback
- Create career development plans
- Encourage conference attendance
- Support certification programs
- Provide learning resources
- Create internal training programs
- Share responsibility for knowledge transfer
- Celebrate learning achievements

### Cross-Team Collaboration
- Hold regular cross-team syncs
- Share architectural decisions
- Collaborate on shared services
- Participate in guilds or communities of practice
- Share reusable components and libraries
- Conduct cross-team code reviews
- Align on standards and practices
- Share infrastructure and tools knowledge
- Collaborate on incident response
- Share success stories and failures

## 56. INFRASTRUCTURE SECURITY HARDENING

### Security Patching
- Implement automated security updates for OS
- Keep all software and dependencies updated
- Subscribe to security advisories
- Patch critical vulnerabilities within 24-48 hours
- Test patches in staging before production
- Maintain patching schedule (weekly/monthly)
- Track patch compliance across infrastructure
- Use automated patch management tools
- Document patching procedures
- Have rollback plan for failed patches

### Vulnerability Scanning
- Implement continuous vulnerability scanning
- Use container image scanning (Trivy, Clair, Snyk, Anchore)
- Scan application dependencies (OWASP Dependency-Check, Snyk)
- Perform infrastructure scanning (Nessus, Qualys)
- Scan IaC templates (Checkov, tfsec, Terrascan)
- Set up automated scanning in CI/CD pipeline
- Define vulnerability SLAs by severity
- Track vulnerability remediation metrics
- Fail builds on critical vulnerabilities
- Regularly review and triage findings

### Security Baselines
- Follow CIS benchmarks for all systems
- Implement NIST cybersecurity framework
- Use security hardening guides (STIGs)
- Disable unnecessary services and ports
- Remove default accounts and passwords
- Implement principle of least privilege
- Use security configuration management
- Regularly audit against baselines
- Automate compliance checking
- Document deviations from baselines

### Network Security
- Implement network segmentation (VLANs, subnets)
- Use private subnets for backend services
- Implement proper firewall rules
- Use Web Application Firewall (WAF)
- Implement DDoS protection (CloudFlare, AWS Shield)
- Use VPN for remote access
- Implement zero-trust networking
- Monitor network traffic for anomalies
- Use network access control lists (NACLs)
- Implement microsegmentation for containers

### Access Control
- Implement multi-factor authentication (MFA) everywhere
- Use single sign-on (SSO) where possible
- Implement role-based access control (RBAC)
- Follow principle of least privilege
- Regularly review and revoke unused access
- Use temporary credentials (STS, IAM roles)
- Implement just-in-time access for privileged operations
- Monitor privileged access usage
- Use bastion hosts for production access
- Implement session recording for audit

### Secrets Management
- Use dedicated secrets managers (Vault, AWS Secrets Manager, Azure Key Vault)
- Implement automatic secrets rotation
- Never hardcode secrets in code or config
- Use environment variables or mounted secrets
- Encrypt secrets at rest and in transit
- Implement secrets access auditing
- Use short-lived credentials when possible
- Implement emergency secrets revocation
- Use different secrets per environment
- Monitor secrets access patterns

### Security Monitoring
- Implement SIEM (Security Information and Event Management)
- Enable CloudTrail, Azure Activity Log, GCP Cloud Audit Logs
- Monitor failed authentication attempts
- Alert on privilege escalation attempts
- Track security group and firewall changes
- Monitor data exfiltration attempts
- Implement file integrity monitoring
- Use intrusion detection systems (IDS)
- Monitor for malware and rootkits
- Implement security dashboards

### Penetration Testing
- Conduct regular penetration testing (annually minimum)
- Perform both external and internal pen tests
- Test web applications, APIs, and infrastructure
- Engage third-party security firms
- Conduct red team exercises
- Test social engineering defenses
- Document and remediate findings
- Retest after remediation
- Share learnings with team
- Implement continuous security testing

### Compliance & Auditing
- Implement audit logging for all systems
- Maintain immutable audit logs
- Regularly review access logs
- Conduct security audits quarterly
- Maintain compliance documentation
- Implement automated compliance checking
- Track security metrics and KPIs
- Conduct internal security reviews
- Prepare for external audits
- Document security controls

## 57. METRICS, KPIS & ADVANCED OBSERVABILITY

### DORA Metrics (DevOps Performance)
- **Deployment Frequency**: How often code is deployed to production
  - Elite: Multiple times per day
  - High: Once per day to once per week
  - Target: Increase frequency over time
- **Lead Time for Changes**: Time from commit to production
  - Elite: Less than one hour
  - High: One day to one week
  - Track and optimize the deployment pipeline
- **Mean Time to Recovery (MTTR)**: Time to restore service after incident
  - Elite: Less than one hour
  - Track incident response time
  - Improve recovery procedures
- **Change Failure Rate**: Percentage of deployments causing failures
  - Elite: 0-15%
  - Monitor and reduce failed deployments
  - Improve testing and validation

### System Performance Metrics
- **Availability & Uptime**
  - Track SLA compliance (99.9%, 99.99%, 99.999%)
  - Monitor uptime per service
  - Calculate downtime impact
  - Track availability trends
- **Response Times**
  - Monitor p50, p95, p99 latencies
  - Track API endpoint response times
  - Monitor database query times
  - Track page load times (LCP, FCP, TTI)
- **Throughput**
  - Requests per second (RPS)
  - Transactions per second (TPS)
  - Data transfer rates
  - Queue processing rates
- **Error Rates**
  - HTTP error rates (4xx, 5xx)
  - Application error rates
  - Database error rates
  - Integration failure rates

### Resource Utilization
- **Compute Resources**
  - CPU utilization (average and peak)
  - Memory usage and available memory
  - Disk I/O and IOPS
  - Network bandwidth usage
- **Scaling Metrics**
  - Auto-scaling events
  - Instance counts over time
  - Container pod counts
  - Queue depths and lag
- **Cost Metrics**
  - Cost per request/transaction
  - Infrastructure costs by service
  - Data transfer costs
  - Database costs (RCU/WCU for DynamoDB, etc.)

### Application Metrics
- **Business Metrics**
  - User registration rates
  - Active users (DAU, MAU)
  - Conversion rates
  - Feature adoption rates
  - Revenue per user
  - Transaction volumes
- **User Experience**
  - Core Web Vitals (LCP, FID, CLS)
  - Apdex scores
  - User satisfaction (NPS, CSAT)
  - Session duration
  - Bounce rates
  - Error impact on users

### Database Metrics
- Connection pool utilization
- Query execution times (slow queries)
- Cache hit ratios
- Replication lag
- Lock waits and deadlocks
- Table and index sizes
- Write and read throughput

### Security Metrics
- Failed authentication attempts
- Access control violations
- Security scan findings
- Patch compliance rate
- Mean time to patch (MTTP)
- Security incident count
- Vulnerability aging

### Developer Productivity
- **Code Quality**
  - Code coverage percentage
  - Technical debt ratio
  - Code churn rate
  - Cyclomatic complexity
- **Development Velocity**
  - Story points completed per sprint
  - Cycle time (ticket to done)
  - Pull request review time
  - Build and test duration
- **Team Health**
  - Sprint completion rate
  - Bug escape rate
  - Production incidents per release
  - Developer satisfaction

### Observability Best Practices
- **Structured Logging**
  - Use JSON format for logs
  - Include correlation IDs
  - Add contextual information
  - Use appropriate log levels
  - Centralize logs (ELK, Splunk, CloudWatch)
- **Distributed Tracing**
  - Implement end-to-end tracing
  - Use OpenTelemetry or similar
  - Track request flows across services
  - Identify bottlenecks
  - Monitor external dependencies
- **Custom Metrics**
  - Define business-specific metrics
  - Track feature usage
  - Monitor critical user journeys
  - Alert on anomalies
  - Create dashboards for stakeholders

### Alerting Strategy
- Define alert thresholds based on SLOs
- Implement multi-level alerting (warning, critical)
- Use alert aggregation to reduce noise
- Set up on-call escalation
- Include runbook links in alerts
- Track alert fatigue metrics
- Review and tune alerts regularly
- Implement intelligent alerting (ML-based)

### Dashboard Design
- Create role-specific dashboards (dev, ops, business)
- Show real-time and historical data
- Include SLO/SLA compliance
- Display error budgets
- Highlight anomalies automatically
- Make dashboards accessible to all
- Keep dashboards up-to-date
- Use consistent visualization standards

## 58. DATA ENGINEERING & ETL PIPELINES

### Pipeline Design Principles
- Design idempotent pipelines (safe to re-run)
- Implement incremental processing when possible
- Use appropriate batch sizes (not too small, not too large)
- Handle late-arriving data properly
- Implement proper error handling and retries
- Use schema evolution strategies
- Design for scalability from the start
- Separate data ingestion, processing, and storage

### Data Quality
- **Validation at Each Stage**
  - Validate data at ingestion point
  - Check data types and formats
  - Verify required fields are present
  - Validate data ranges and constraints
  - Check referential integrity
- **Data Quality Checks**
  - Completeness: All expected data present
  - Accuracy: Data values are correct
  - Consistency: Data doesn't contradict itself
  - Timeliness: Data is up-to-date
  - Validity: Data conforms to schema
  - Uniqueness: No unintended duplicates
- **Data Quality Metrics**
  - Track data quality scores
  - Monitor quality trends over time
  - Alert on quality degradation
  - Document known data issues

### ETL Best Practices
- **Extract**
  - Use incremental extraction when possible
  - Implement change data capture (CDC)
  - Handle API rate limits properly
  - Implement extraction monitoring
  - Use appropriate extraction patterns (full, incremental, delta)
- **Transform**
  - Keep transformations simple and testable
  - Document transformation logic
  - Use SQL/DataFrame operations when possible
  - Implement data lineage tracking
  - Handle null values consistently
  - Normalize data formats (dates, currencies)
  - Implement data enrichment carefully
- **Load**
  - Use bulk loading for better performance
  - Implement upsert logic properly
  - Handle duplicates appropriately
  - Validate after loading
  - Implement transaction handling
  - Use appropriate loading patterns (append, replace, upsert)

### Data Pipeline Orchestration
- Use orchestration tools (Airflow, Dagster, Prefect, Step Functions)
- Define clear task dependencies
- Implement proper task retries with backoff
- Use task groups for organization
- Implement SLA monitoring
- Handle pipeline failures gracefully
- Implement data quality gates
- Use dynamic task generation when appropriate
- Schedule pipelines appropriately
- Implement pipeline versioning

### Schema Management
- Version control schema definitions
- Implement schema validation
- Handle schema evolution (backward/forward compatibility)
- Use schema registry when appropriate
- Document schema changes
- Implement schema migration strategies
- Use appropriate data formats (Parquet, Avro, ORC)
- Validate schema before processing

### Data Lineage & Governance
- Track data lineage from source to destination
- Document data transformations
- Implement data cataloging
- Define data ownership
- Implement data retention policies
- Comply with data regulations (GDPR, CCPA)
- Implement data masking for sensitive data
- Audit data access
- Document data quality rules
- Implement metadata management

### Performance Optimization
- Partition data appropriately (by date, region, etc.)
- Use columnar formats for analytics (Parquet, ORC)
- Implement data compression
- Optimize join operations
- Use appropriate cluster sizes
- Implement caching where beneficial
- Monitor and optimize shuffle operations
- Use broadcast joins for small tables
- Implement predicate pushdown
- Optimize file sizes (avoid small files)

### Monitoring & Alerting
- Monitor pipeline execution duration
- Track data volumes processed
- Monitor error rates and types
- Alert on pipeline failures
- Track data freshness/latency
- Monitor resource utilization
- Implement data quality alerts
- Track SLA compliance
- Monitor costs per pipeline
- Create pipeline health dashboards

### Error Handling & Recovery
- Implement comprehensive error handling
- Use dead letter queues for failed records
- Implement automatic retries with exponential backoff
- Log errors with sufficient context
- Implement manual intervention workflows
- Design for partial failures
- Implement circuit breakers for external dependencies
- Create error recovery runbooks
- Track error patterns
- Implement data reconciliation processes

### Testing Data Pipelines
- Write unit tests for transformation logic
- Implement integration tests for full pipelines
- Use test data that represents production
- Test edge cases and error scenarios
- Implement data quality tests
- Test schema evolution
- Validate data lineage
- Test rollback procedures
- Implement smoke tests for quick validation
- Use test-driven development for pipelines

## 59. CI/CD PIPELINE BEST PRACTICES

### Pipeline as Code
- Use declarative pipeline definitions (Jenkinsfile, .gitlab-ci.yml, .github/workflows)
- Version control all pipeline configurations
- Use pipeline templates for consistency
- Implement pipeline validation and linting
- Use modular pipeline components
- Document pipeline stages and purposes
- Implement pipeline as code reviews
- Use environment-specific configurations

### Pipeline Stages & Structure
- **Build Stage**: Compile, package, create artifacts
- **Test Stage**: Unit, integration, contract tests
- **Security Scan Stage**: SAST, DAST, dependency scanning
- **Quality Gate Stage**: Code coverage, quality metrics
- **Deploy Stage**: Infrastructure, application deployment
- **Verification Stage**: Smoke tests, health checks
- Use parallel execution for independent stages
- Implement proper stage ordering and dependencies

### Artifact Management
- Use artifact repositories (Artifactory, Nexus, ECR, ACR)
- Implement semantic versioning for artifacts
- Tag artifacts with build metadata (git SHA, build number)
- Implement artifact retention policies
- Use immutable artifacts (never overwrite)
- Scan artifacts for vulnerabilities before deployment
- Implement artifact promotion across environments
- Track artifact lineage and provenance

### Deployment Strategies
- **Blue-Green Deployment**: Zero-downtime deployments
  - Maintain two identical environments
  - Switch traffic after successful deployment
  - Quick rollback capability
- **Canary Deployment**: Gradual rollout with monitoring
  - Deploy to small percentage of users first
  - Monitor metrics and errors
  - Gradually increase traffic if successful
  - Automatic rollback on anomalies
- **Rolling Updates**: Sequential updates with health checks
  - Update instances one at a time or in batches
  - Verify health before proceeding
  - Maintain minimum available instances
- **Feature Toggle Deployment**: Deploy code without activating features
  - Use feature flags for activation
  - Test in production with limited users
  - Independent deploy and release cycles

### Pipeline Security
- Implement least privilege for pipeline credentials
- Use secrets management (Vault, AWS Secrets Manager)
- Never commit secrets to version control
- Rotate credentials regularly
- Implement RBAC for pipeline access
- Audit pipeline executions
- Scan for secrets in code before building
- Use ephemeral credentials when possible
- Implement code signing for artifacts
- Verify artifact integrity before deployment

### Build Optimization
- Implement build caching (dependencies, layers)
- Use incremental builds when possible
- Parallelize independent build steps
- Optimize Docker image layers
- Use multi-stage builds for smaller images
- Implement build artifact caching
- Monitor and optimize build times
- Use build matrices for multiple configurations

### Testing in Pipeline
- Run fast tests first (fail fast principle)
- Implement test parallelization
- Use appropriate test timeouts
- Implement flaky test detection and quarantine
- Generate and publish test reports
- Track test coverage trends
- Implement contract tests for APIs
- Run security tests (SAST, DAST, dependency scanning)
- Implement performance tests for critical paths

### Deployment Gates & Approvals
- Implement automated quality gates (coverage, security, performance)
- Use manual approval gates for production
- Implement time-based deployment windows
- Use change advisory board (CAB) approvals when required
- Implement automated compliance checks
- Verify pre-deployment checklist completion
- Implement deployment notifications
- Track approval workflow and history

### Multi-Environment Strategy
- Use environment parity (dev, staging, production similar)
- Implement environment-specific configurations
- Use different approval levels per environment
- Implement progressive deployment (dev  staging  prod)
- Use separate credentials per environment
- Implement environment isolation
- Track environment drift
- Document environment differences

### Rollback Automation
- Implement one-click rollback capability
- Maintain previous version artifacts
- Automate rollback on failure detection
- Test rollback procedures regularly
- Implement database migration rollback
- Document rollback procedures
- Monitor system during rollback
- Notify team on automatic rollbacks

### Pipeline Monitoring & Observability
- Track pipeline execution metrics (duration, success rate)
- Monitor build queue lengths
- Alert on pipeline failures
- Track deployment frequency (DORA metric)
- Monitor artifact sizes over time
- Implement pipeline performance dashboards
- Track mean time to recovery for failed deployments
- Monitor resource utilization during builds

### Infrastructure Provisioning in Pipelines
- Use Infrastructure as Code in pipelines
- Implement infrastructure validation before deployment
- Plan infrastructure changes before applying
- Implement infrastructure testing (Terratest, InSpec)
- Use separate pipelines for infrastructure and application
- Implement infrastructure drift detection
- Track infrastructure changes over time
- Implement infrastructure cost estimation

## 60. SRE (SITE RELIABILITY ENGINEERING) PRACTICES

### Service Level Indicators (SLI)
- **Availability SLI**: Percentage of successful requests
  - Example: 99.9% of requests return 2xx status codes
- **Latency SLI**: Response time percentiles
  - Example: 95% of requests complete within 200ms
- **Quality SLI**: Correctness of responses
  - Example: 99.99% of responses are correct
- **Throughput SLI**: Requests handled per second
- Choose SLIs that matter to users
- Make SLIs measurable and objective
- Collect SLI data continuously
- Use multiple SLIs for comprehensive coverage

### Service Level Objectives (SLO)
- Set realistic SLOs based on user expectations
- Define SLO targets (e.g., 99.9% availability)
- Set measurement windows (rolling 30 days, monthly)
- Define consequences of SLO violations
- Review and adjust SLOs quarterly
- Make SLOs visible to entire organization
- Align SLOs with business requirements
- Document SLO calculation methodology
- Example SLOs:
  - API availability: 99.9% over 30 days
  - API latency: p99 < 500ms
  - Error rate: < 0.1% of requests

### Service Level Agreements (SLA)
- SLA must be less strict than SLO (buffer room)
- Define customer-facing commitments
- Document SLA penalties and credits
- Implement SLA monitoring and reporting
- Communicate SLA status to customers
- Track SLA compliance history
- Implement automated SLA reports
- Review SLAs annually with stakeholders

### Error Budgets
- Calculate error budget: (100% - SLO)  total requests
- Track error budget consumption in real-time
- Stop feature releases when error budget exhausted
- Use error budget for risk vs velocity decisions
- Implement error budget policies
- Share error budget status with team
- Example: 99.9% SLO = 0.1% error budget = 43.2 minutes downtime/month
- Prioritize reliability work when budget low
- Use error budget for experimentation decisions

### Error Budget Burn Rate
- Monitor how fast error budget is being consumed
- Alert on accelerated burn rate
- Implement different alert levels:
  - Fast burn: 2% budget in 1 hour (critical alert)
  - Medium burn: 5% budget in 6 hours (warning)
  - Slow burn: 10% budget in 3 days (info)
- Automate responses to high burn rates
- Track burn rate trends

### Toil Automation
- Identify repetitive manual work (toil)
- Measure time spent on toil (target: <50% of time)
- Prioritize automation of high-toil tasks
- Implement runbook automation
- Use chatops for common operations
- Automate incident response procedures
- Eliminate manual capacity management
- Automate deployment processes
- Track toil reduction over time
- Celebrate toil elimination wins

### Incident Management (Expanded)
- Define incident severity levels (P0-P4)
- Implement incident commander role
- Use structured communication channels
- Maintain incident timeline and notes
- Implement incident response workflows
- Use war rooms for critical incidents
- Escalate based on severity and duration
- Implement customer communication protocols
- Track MTTR (Mean Time To Recovery)
- Document incident resolution steps

### Blameless Post-Mortems
- Conduct post-mortems for all major incidents
- Focus on systems and processes, not individuals
- Document timeline of events
- Identify root cause and contributing factors
- Create action items with owners and deadlines
- Share post-mortems widely
- Track action item completion
- Learn from near-misses
- Create library of post-mortems
- Review trends across incidents

### On-Call Best Practices (Expanded)
- Implement fair on-call rotation (1 week maximum)
- Provide on-call compensation or time-off
- Maintain on-call runbooks for common issues
- Implement on-call handoff procedures
- Limit on-call hours (avoid burnout)
- Provide on-call training before first shift
- Use tiered on-call escalation
- Implement follow-the-sun on-call for global teams
- Track on-call metrics (pages, response time, resolution time)
- Improve alerts to reduce false positives

### Capacity Planning
- Monitor resource utilization trends
- Forecast capacity needs (3-12 months ahead)
- Implement capacity alerts and thresholds
- Plan for peak loads (seasonal, marketing campaigns)
- Use load testing to validate capacity
- Implement auto-scaling for dynamic capacity
- Document capacity limits and bottlenecks
- Review capacity quarterly
- Plan infrastructure growth proactively
- Consider organic growth and new features

### Production Readiness Reviews
- Conduct reviews before launching new services
- Review architecture and design
- Verify monitoring and alerting coverage
- Validate SLI/SLO definitions
- Check disaster recovery procedures
- Review security controls
- Verify scalability testing
- Check documentation completeness
- Validate runbook coverage
- Ensure team training completion
- Create production readiness checklist

### Reliability Engineering Culture
- Make reliability everyone's responsibility
- Allocate 50% SRE time for engineering work
- Implement reliability champions in product teams
- Share reliability metrics transparently
- Celebrate reliability wins
- Learn from failures without blame
- Invest in automation and tooling
- Balance feature velocity with reliability
- Implement chaos engineering practices
- Foster collaboration between dev and ops

## 61. EVENT-DRIVEN ARCHITECTURE & EVENT SOURCING

### Event-Driven Architecture Principles
- Design events as immutable facts
- Use events to communicate between services
- Implement event-driven microservices
- Decouple services through events
- Use events for audit trails
- Design for eventual consistency
- Implement compensating transactions
- Use events for analytics and reporting

### Event Design Best Practices
- Use clear, descriptive event names (PastTense: OrderPlaced, UserRegistered)
- Include event metadata (timestamp, event ID, correlation ID, causation ID)
- Make events immutable
- Include complete state in events (avoid requiring additional lookups)
- Use semantic versioning for event schemas
- Document event purpose and usage
- Include business context in events
- Avoid coupling events to internal implementation

### Domain Events vs Integration Events
- **Domain Events**: Internal to bounded context
  - Represent business facts within domain
  - May not leave the service boundary
  - Can be more detailed and granular
- **Integration Events**: Cross-boundary communication
  - Published to external consumers
  - More stable contract
  - Include only necessary information
  - Versioned carefully

### Event Sourcing Patterns
- Store events as the source of truth
- Rebuild state by replaying events
- Implement event store (EventStore, Kafka, DynamoDB Streams)
- Create projections/read models from events
- Implement snapshots for performance
- Handle event versioning and migration
- Implement upcasting for old events
- Design aggregate boundaries carefully

### Event Store Selection
- **EventStoreDB**: Purpose-built event store
  - Optimistic concurrency control
  - Built-in projections
  - Supports event subscriptions
- **Apache Kafka**: Distributed event streaming
  - High throughput
  - Durable event log
  - Supports event replay
- **AWS DynamoDB Streams**: Serverless event streaming
  - Integrated with DynamoDB
  - Automatic scaling
- **PostgreSQL/MySQL**: Using as event store
  - Leverage existing infrastructure
  - ACID guarantees
  - Requires careful schema design

### CQRS (Command Query Responsibility Segregation)
- Separate write models (commands) from read models (queries)
- Optimize read and write models independently
- Use different data stores for reads and writes if needed
- Implement eventual consistency between models
- Use events to synchronize read models
- Scale read and write sides independently
- Implement separate validation for commands
- Use projections for complex queries

### Event Replay & Reprocessing
- Design events to be replayable
- Implement event versioning for backward compatibility
- Use snapshots to improve replay performance
- Implement event filtering for targeted replay
- Test replay procedures regularly
- Document replay scenarios
- Implement replay monitoring
- Consider replay impact on external systems

### Event Ordering & Idempotency
- Ensure events are processed in order when required
- Use partition keys for ordering guarantees (Kafka)
- Implement idempotent event handlers
- Use event IDs for deduplication
- Handle out-of-order events gracefully
- Implement at-least-once delivery
- Use exactly-once semantics when possible
- Document ordering requirements

### Event Versioning
- Use semantic versioning for event schemas
- Support multiple event versions simultaneously
- Implement event upcasting (old to new format)
- Implement event downcasting when needed
- Document breaking vs non-breaking changes
- Test version compatibility
- Plan deprecation strategy for old versions
- Communicate version changes to consumers

### Event Retention & Archival
- Define retention policies per event type
- Implement event archival for compliance
- Use tiered storage for old events
- Implement event compaction when appropriate
- Consider legal and regulatory requirements
- Plan for event deletion (GDPR right to be forgotten)
- Document retention policies
- Implement event anonymization when needed

### Saga Patterns for Distributed Transactions
- **Choreography**: Services react to events independently
  - Decentralized decision making
  - Simple for straightforward workflows
  - Can be hard to understand complex flows
- **Orchestration**: Central coordinator manages saga
  - Explicit workflow definition
  - Easier to understand and debug
  - Single point of failure (mitigate with HA)
- Implement compensating transactions for rollback
- Use timeouts and retries
- Implement saga state management
- Monitor saga completion rates
- Document saga workflows

### Event-Driven Security
- Implement authentication for event publishers
- Use authorization for event consumers
- Encrypt sensitive data in events
- Implement event schema validation
- Audit event access and modifications
- Use secure channels for event transmission
- Implement event signing for integrity
- Monitor suspicious event patterns

### Event Monitoring & Observability
- Track event publishing rates
- Monitor event processing latency
- Track failed event processing
- Implement event flow tracing
- Monitor event store performance
- Alert on event processing delays
- Track event consumer lag
- Implement event replay monitoring
- Create event flow dashboards

## 62. INFRASTRUCTURE AS CODE (IaC) DETAILED

### Terraform Best Practices
- Use Terraform workspaces for environments
- Implement remote state management (S3, Terraform Cloud)
- Enable state locking (DynamoDB, Consul)
- Use modules for reusable infrastructure components
- Version control all Terraform code
- Implement terraform fmt and terraform validate in CI/CD
- Use variables for environment-specific values
- Implement output values for resource references
- Use data sources for existing resources
- Implement resource tagging standards
- Use terraform plan before apply
- Implement targeted applies when needed
- Document module inputs and outputs
- Use semantic versioning for modules

### Terraform Module Design
- Create small, focused modules
- Implement module versioning
- Document module usage with examples
- Define clear input variables
- Provide sensible defaults
- Use output values for resource attributes
- Implement module testing
- Publish modules to registry
- Keep modules DRY (Don't Repeat Yourself)
- Follow naming conventions

### State Management
- Store state remotely (never in version control)
- Implement state encryption
- Enable state versioning
- Use state locking to prevent conflicts
- Implement state backup strategies
- Separate state per environment
- Use separate state files per component when appropriate
- Document state file locations
- Implement state access controls
- Plan for state migration

### IaC Testing
- **Unit Testing**: Test individual modules (Terratest)
- **Integration Testing**: Test complete infrastructure
- **Compliance Testing**: Verify security and policy compliance
- Use static analysis (tflint, Checkov, tfsec, Terrascan)
- Implement automated testing in CI/CD
- Test infrastructure provisioning in non-prod
- Validate infrastructure after deployment
- Test disaster recovery procedures
- Implement infrastructure smoke tests
- Test rollback procedures

### CloudFormation Best Practices
- Use nested stacks for modularity
- Implement stack policies for protection
- Use change sets to preview changes
- Implement stack outputs for cross-stack references
- Use parameters for flexibility
- Implement conditions for environment differences
- Use mappings for region-specific values
- Implement DeletionPolicy for critical resources
- Use CloudFormation drift detection
- Implement stack lifecycle management

### Pulumi Best Practices
- Use familiar programming languages
- Implement stack management (dev, staging, prod)
- Use Pulumi state management
- Implement component resources for reusability
- Use configuration and secrets management
- Implement stack outputs
- Use Pulumi policy as code
- Implement automated testing
- Use stack references for dependencies
- Implement continuous delivery

### Ansible Best Practices
- Use role-based organization
- Implement inventory management
- Use variables and facts appropriately
- Implement idempotent playbooks
- Use handlers for service restarts
- Implement error handling with blocks
- Use tags for selective execution
- Implement dry-run mode testing
- Use Ansible Vault for secrets
- Implement playbook testing (Molecule)

### IaC Security Scanning
- Scan for hardcoded secrets (git-secrets, TruffleHog)
- Scan for security misconfigurations (Checkov, tfsec, Terrascan)
- Implement policy as code (OPA, Sentinel)
- Scan for compliance violations
- Integrate security scanning in CI/CD
- Fail builds on critical security issues
- Generate security reports
- Track security findings over time
- Implement remediation workflows

### Drift Detection & Remediation
- Implement automated drift detection
- Schedule regular drift checks
- Alert on detected drift
- Document expected vs actual state
- Implement drift remediation procedures
- Track drift occurrences
- Investigate root causes of drift
- Update IaC to match manual changes
- Prevent unauthorized manual changes

### IaC Change Management
- Implement PR reviews for all changes
- Use meaningful commit messages
- Document why changes are made
- Implement approval workflows
- Use plan outputs in PRs
- Test changes in non-production first
- Implement gradual rollout for large changes
- Maintain change log
- Implement change windows for production
- Communicate changes to stakeholders

### Cost Estimation
- Implement cost estimation before deployment (Infracost)
- Track infrastructure costs over time
- Set cost budgets and alerts
- Optimize resource sizing
- Review and remove unused resources
- Implement cost allocation tags
- Forecast future costs
- Compare actual vs estimated costs
- Implement cost optimization recommendations

### IaC Documentation
- Document infrastructure architecture
- Maintain README for each module
- Document prerequisites and dependencies
- Include usage examples
- Document variable purposes and defaults
- Maintain runbooks for common tasks
- Document troubleshooting procedures
- Keep architecture diagrams updated
- Document disaster recovery procedures

## 63. gRPC & PROTOCOL BUFFERS

### Protocol Buffers Schema Design
- Use clear, descriptive message and field names
- Use semantic versioning for proto files
- Add comments and documentation to schemas
- Use appropriate field types
- Implement field numbering strategy (reserve numbers)
- Use enums for fixed sets of values
- Implement nested messages when appropriate
- Use repeated fields for arrays
- Use map fields for key-value pairs
- Plan for schema evolution

### Backward & Forward Compatibility
- Never change field numbers
- Don't remove required fields
- Don't change field types
- Add new fields as optional
- Reserve deleted field numbers and names
- Use default values carefully
- Test compatibility with old clients/servers
- Document breaking changes
- Implement version negotiation if needed
- Use separate versions for breaking changes

### gRPC Service Definition
- Define clear service contracts
- Use descriptive service and method names
- Group related methods in services
- Implement appropriate request/response messages
- Use streaming when appropriate
- Document service behavior
- Define error responses
- Implement service versioning
- Use packages for organization
- Keep services focused and cohesive

### Streaming Patterns
- **Server Streaming**: Server sends multiple responses
  - Use for large datasets, real-time updates
  - Example: Stock price updates, log streaming
- **Client Streaming**: Client sends multiple requests
  - Use for uploading large files, batching
  - Example: Upload multiple files, send telemetry
- **Bidirectional Streaming**: Both send multiple messages
  - Use for real-time communication
  - Example: Chat applications, collaborative editing
- Implement proper stream lifecycle management
- Handle stream cancellation gracefully
- Implement flow control
- Test streaming scenarios thoroughly

### gRPC Error Handling
- Use standard gRPC status codes
- Provide meaningful error messages
- Use error details for additional context
- Implement retry logic with exponential backoff
- Handle deadline exceeded errors
- Implement circuit breakers for failing services
- Log errors with context
- Return appropriate status codes
- Implement error interceptors
- Test error scenarios

### gRPC Interceptors & Middleware
- Implement authentication interceptors
- Add logging and tracing interceptors
- Implement metrics collection
- Add request validation
- Implement rate limiting
- Add error handling middleware
- Implement request/response transformation
- Add caching layers
- Implement timeout management
- Chain interceptors appropriately

### Load Balancing for gRPC
- Use client-side load balancing
- Implement connection pooling
- Use service discovery (Consul, etcd)
- Implement health checking
- Use round-robin or least-request algorithms
- Handle connection failures gracefully
- Implement retry logic
- Monitor connection states
- Use load balancer proxies when needed (Envoy)
- Test load balancing behavior

### gRPC Security
- Implement TLS/SSL for encryption
- Use mutual TLS (mTLS) for authentication
- Implement token-based authentication (JWT)
- Use OAuth 2.0 for authorization
- Implement API key authentication
- Encrypt sensitive data in messages
- Implement rate limiting per client
- Monitor for security threats
- Use security interceptors
- Follow principle of least privilege

### Performance Optimization
- Use HTTP/2 features (multiplexing, header compression)
- Implement connection reuse
- Use binary serialization (Protocol Buffers)
- Minimize message sizes
- Implement compression when beneficial
- Use streaming for large data transfers
- Implement client-side caching
- Optimize serialization/deserialization
- Monitor and profile performance
- Use connection pooling

### gRPC vs REST Decision Matrix
**Use gRPC when:**
- Need high performance and low latency
- Require strong typing and contracts
- Need bidirectional streaming
- Building microservices communication
- Have bandwidth constraints

**Use REST when:**
- Need browser compatibility
- Require human-readable data
- Building public APIs
- Need simple debugging
- Have simpler requirements

### Testing gRPC Services
- Write unit tests for service logic
- Implement integration tests with gRPC clients
- Test streaming scenarios
- Test error handling and edge cases
- Implement contract testing
- Test backward compatibility
- Load test gRPC services
- Test security configurations
- Test with various client implementations
- Use grpcurl for manual testing

### Monitoring & Observability
- Implement request/response logging
- Track method call rates and latencies
- Monitor error rates by method
- Implement distributed tracing
- Track connection metrics
- Monitor streaming performance
- Implement health checks
- Create gRPC-specific dashboards
- Alert on anomalies
- Track SLA compliance

## 64. API CONTRACT TESTING & SCHEMA MANAGEMENT

### OpenAPI/Swagger Best Practices
- Use OpenAPI 3.x specification
- Define all endpoints, methods, parameters
- Document request and response schemas
- Include error response schemas
- Use examples for clarity
- Implement security definitions
- Version API specifications
- Generate client SDKs from specs
- Use tools like Swagger Editor
- Keep specs in version control

### API Contract Versioning
- Use semantic versioning for APIs
- Implement backward compatible changes when possible
- Document all breaking changes
- Provide migration guides for major versions
- Support multiple versions simultaneously
- Deprecate old versions gracefully
- Communicate version changes to consumers
- Track API version usage
- Plan version sunset dates
- Test across versions

### Breaking vs Non-Breaking Changes
**Breaking Changes:**
- Removing endpoints or fields
- Changing field types
- Adding required fields
- Changing authentication requirements
- Changing error responses

**Non-Breaking Changes:**
- Adding new endpoints
- Adding optional fields
- Adding new error codes
- Improving performance
- Fixing bugs

### Consumer-Driven Contract Testing
- Use Pact or similar tools
- Define contracts from consumer perspective
- Verify provider against contracts
- Integrate contract tests in CI/CD
- Version contracts alongside code
- Share contracts between teams
- Implement contract test reporting
- Update contracts when requirements change
- Test backward compatibility
- Document contract requirements

### Schema Validation in CI/CD
- Validate API specs in build pipeline
- Check for breaking changes automatically
- Generate changelogs from spec changes
- Fail builds on undocumented changes
- Validate request/response examples
- Check schema consistency
- Implement linting for specs
- Generate documentation automatically
- Notify consumers of changes
- Track schema evolution

### API Deprecation Strategies
- Announce deprecation well in advance (6-12 months)
- Provide clear migration path
- Return deprecation headers (Sunset, Deprecation)
- Document deprecated endpoints clearly
- Monitor usage of deprecated APIs
- Support deprecated versions for transition period
- Provide migration tools if possible
- Communicate through multiple channels
- Track migration progress
- Archive deprecated documentation

### API Changelog Management
- Maintain detailed changelog
- Document all changes (features, fixes, deprecations)
- Use semantic versioning for releases
- Include migration guides
- Publish changelog with releases
- Make changelog easily accessible
- Use tools like API Changelog Generator
- Categorize changes clearly
- Include dates and version numbers
- Link to detailed documentation

### Schema Evolution Best Practices
- Plan for evolution from the start
- Use extensible schemas
- Implement version negotiation
- Support content negotiation
- Use hypermedia when appropriate
- Document evolution strategy
- Test with old and new schemas
- Implement graceful degradation
- Communicate changes clearly
- Monitor schema usage patterns

### API Documentation
- Use auto-generated documentation (Swagger UI, ReDoc)
- Include code examples in multiple languages
- Provide getting started guides
- Document authentication flows
- Include rate limiting information
- Provide interactive API explorer
- Keep documentation up-to-date
- Include troubleshooting guides
- Document common use cases
- Provide SDKs and client libraries

## 65. SERVICE MESH PATTERNS

### Service Mesh Overview
- Implement service-to-service communication infrastructure
- Separate network concerns from application logic
- Provide observability, security, and reliability features
- Use sidecar proxy pattern (Envoy)
- Centralize policy enforcement
- Implement without code changes
- Support polyglot services
- Enable gradual adoption

### Istio Best Practices
- Use Istio for large microservices deployments
- Implement automatic sidecar injection
- Use VirtualServices for traffic routing
- Implement DestinationRules for load balancing
- Use Gateways for ingress/egress
- Implement ServiceEntries for external services
- Use PeerAuthentication for mTLS
- Implement AuthorizationPolicies for access control
- Monitor with Istio telemetry
- Start with pilot-only deployment

### Linkerd Configuration
- Use Linkerd for simpler, lighter service mesh
- Implement automatic proxy injection
- Use ServiceProfiles for traffic splitting
- Implement TrafficSplits for canary deployments
- Use NetworkPolicies for security
- Implement mTLS automatically
- Monitor with Linkerd dashboard
- Use Linkerd for golden metrics (success rate, latency, throughput)
- Implement gradual rollout
- Keep configuration minimal

### Traffic Management
- **Traffic Routing**: Route requests based on headers, URLs
- **Traffic Splitting**: A/B testing, canary deployments
- **Traffic Mirroring**: Test changes with production traffic
- **Traffic Shifting**: Gradual migration between versions
- Implement weighted routing
- Use header-based routing
- Implement geo-based routing
- Configure timeout and retry policies
- Implement connection pooling
- Monitor traffic patterns

### Security with Service Mesh
- Implement automatic mutual TLS (mTLS)
- Encrypt all service-to-service communication
- Implement certificate rotation
- Use identity-based authentication
- Implement authorization policies
- Define service-to-service access controls
- Monitor certificate health
- Implement zero-trust security
- Audit security policies
- Test security configurations

### Observability Features
- Automatic metrics collection (RED metrics)
- Distributed tracing integration (Jaeger, Zipkin)
- Service dependency visualization
- Access logging for all requests
- Golden signals monitoring (latency, traffic, errors, saturation)
- Create service mesh dashboards
- Implement service-level monitoring
- Track mesh control plane health
- Monitor sidecar resource usage

### Circuit Breaking Configuration
- Implement connection pool limits
- Set concurrent request limits
- Configure timeout settings
- Define outlier detection rules
- Set maximum retry attempts
- Implement ejection policies
- Monitor circuit breaker status
- Test circuit breaker behavior
- Tune thresholds based on metrics
- Document circuit breaker policies

### Retry Policies
- Configure retry attempts per service
- Implement exponential backoff
- Set retry timeouts
- Define retry conditions (status codes)
- Implement retry budgets
- Monitor retry rates
- Prevent retry storms
- Test retry behavior
- Document retry policies

### Timeout Configuration
- Set request timeouts per service
- Implement connection timeouts
- Configure idle timeouts
- Set streaming timeouts
- Balance timeouts with retries
- Monitor timeout occurrences
- Adjust timeouts based on SLOs
- Test timeout scenarios
- Document timeout policies

### Service Mesh vs API Gateway
**Service Mesh:**
- East-west traffic (service-to-service)
- Internal microservices communication
- Focuses on reliability, security, observability
- Sidecar proxy per service

**API Gateway:**
- North-south traffic (external-to-internal)
- External client access
- Focuses on routing, authentication, rate limiting
- Centralized gateway

**Use both:** API Gateway for external traffic, Service Mesh for internal

### Service Mesh Adoption Strategy
- Start with observability features
- Enable mTLS gradually
- Implement traffic management policies
- Add advanced features incrementally
- Test in non-production first
- Monitor resource overhead
- Train team on service mesh concepts
- Document service mesh architecture
- Plan for upgrade and maintenance
- Measure ROI of service mesh

## 66. WEBHOOKS BEST PRACTICES

### Webhook Security
- Implement request signing (HMAC signatures)
- Verify webhook signatures on receipt
- Use HTTPS for all webhook endpoints
- Implement IP whitelisting when possible
- Use API keys for authentication
- Rotate secrets regularly
- Validate payload structure
- Implement rate limiting
- Log all webhook requests
- Monitor for suspicious patterns

### Webhook Payload Design
- Include event type and timestamp
- Add unique event ID
- Include webhook version
- Add signature for verification
- Keep payload size reasonable
- Include only necessary data
- Use consistent data structure
- Document payload schema
- Support payload format versioning
- Provide payload examples

### Retry Strategies
- Implement exponential backoff (1s, 2s, 4s, 8s, 16s)
- Set maximum retry attempts (3-5)
- Implement timeout for webhook delivery
- Queue failed webhooks for retry
- Provide webhook delivery status
- Implement dead letter queue
- Notify sender of delivery failures
- Allow manual retry
- Log all retry attempts
- Monitor retry success rates

### Idempotency Handling
- Use unique event IDs
- Implement deduplication on receiver
- Handle duplicate deliveries gracefully
- Store processed event IDs
- Set deduplication window
- Return 200 for duplicate events
- Document idempotency guarantees
- Test duplicate scenarios
- Clean up old event IDs

### Webhook Reliability
- Implement delivery confirmation
- Use durable message queues
- Implement at-least-once delivery
- Provide webhook delivery dashboard
- Track delivery success rates
- Monitor delivery latency
- Implement health checks for endpoints
- Handle endpoint failures gracefully
- Provide webhook history
- Support webhook replay

### Webhook Versioning
- Version webhook payload formats
- Support multiple versions simultaneously
- Communicate version changes
- Provide migration guides
- Deprecate old versions gracefully
- Include version in webhook headers
- Document version differences
- Test across versions
- Track version usage

### Testing Webhook Endpoints
- Provide webhook testing tools
- Support test mode/sandbox
- Generate test events
- Validate endpoint responses
- Test error scenarios
- Verify security implementation
- Load test webhook endpoints
- Test idempotency
- Validate retry behavior
- Document testing procedures

### Webhook Monitoring
- Track webhook delivery attempts
- Monitor success/failure rates
- Track delivery latency
- Alert on high failure rates
- Monitor endpoint availability
- Track retry attempts
- Monitor payload sizes
- Create webhook dashboards
- Alert on anomalies
- Track webhook usage patterns

### Webhook Documentation
- Document all webhook events
- Provide payload examples
- Document signature verification
- Include setup instructions
- Document retry behavior
- Provide troubleshooting guide
- Include security best practices
- Document versioning strategy
- Provide code examples
- Keep documentation updated

## 67. GREEN COMPUTING & SUSTAINABILITY

### Energy-Efficient Coding
- Choose efficient algorithms (lower time complexity)
- Optimize database queries to reduce CPU cycles
- Minimize network data transfers
- Use lazy loading and pagination
- Cache frequently accessed data
- Optimize image and asset sizes
- Reduce redundant computations
- Profile and optimize hot paths
- Use efficient data structures
- Minimize memory allocations

### Carbon-Aware Computing
- Schedule batch jobs during low-carbon electricity hours
- Use cloud regions with renewable energy
- Implement carbon-aware load balancing
- Defer non-critical workloads to green hours
- Monitor carbon intensity of compute
- Use Carbon Aware SDK
- Choose green cloud providers
- Track carbon footprint metrics
- Set carbon reduction goals
- Report on sustainability metrics

### Resource Optimization
- Right-size infrastructure (avoid over-provisioning)
- Use auto-scaling to match demand
- Shut down unused environments
- Use spot instances for batch workloads
- Implement efficient caching
- Optimize container images
- Use serverless for sporadic workloads
- Consolidate workloads
- Monitor resource utilization
- Eliminate resource waste

### Sustainable Architecture
- Design for energy efficiency
- Use edge computing to reduce data transfer
- Implement content delivery networks (CDN)
- Optimize API calls
- Use asynchronous processing
- Implement data lifecycle management
- Archive old data efficiently
- Use tiered storage
- Optimize backup strategies
- Plan for long-term sustainability

### Green Cloud Practices
- Choose regions with renewable energy (AWS Oregon, GCP Belgium, Azure Sweden)
- Use Google Cloud Carbon Footprint
- Monitor AWS Customer Carbon Footprint Tool
- Use Azure Sustainability Calculator
- Select carbon-neutral cloud providers
- Track infrastructure carbon emissions
- Set carbon budgets
- Optimize for carbon efficiency
- Prefer managed services (better utilization)
- Consider carbon in architecture decisions

### Data Center Efficiency
- Use Power Usage Effectiveness (PUE) metrics
- Prefer providers with low PUE (<1.2)
- Use providers with renewable energy
- Consider water usage effectiveness
- Choose energy-efficient hardware
- Optimize cooling strategies
- Use waste heat recovery when possible
- Monitor energy efficiency
- Set efficiency targets

### Sustainable Development Practices
- Implement green CI/CD (efficient builds)
- Optimize test suites (reduce runtime)
- Use build caching extensively
- Minimize artifact sizes
- Reduce docker image layers
- Use incremental builds
- Parallelize when beneficial
- Monitor CI/CD energy usage
- Optimize development environments
- Use efficient local tools

### Metrics & Monitoring
- Track energy consumption metrics
- Monitor carbon emissions
- Measure PUE (Power Usage Effectiveness)
- Track data transfer volumes
- Monitor compute efficiency
- Measure storage efficiency
- Track cooling efficiency
- Create sustainability dashboards
- Set green computing KPIs
- Report on sustainability goals

### Sustainability Culture
- Educate team on green computing
- Include sustainability in design reviews
- Set sustainability goals
- Reward green innovations
- Share sustainability metrics
- Celebrate efficiency improvements
- Include carbon cost in decisions
- Promote sustainable practices
- Lead by example
- Collaborate on green initiatives

## 68. COMPLIANCE FRAMEWORKS DETAILED

### SOC 2 Type II Compliance
- Implement security controls
- Define trust service criteria (Security, Availability, Processing Integrity, Confidentiality, Privacy)
- Document policies and procedures
- Implement access controls
- Monitor system availability
- Implement change management
- Conduct risk assessments
- Implement incident response
- Maintain audit logs
- Conduct regular security reviews
- Prepare for auditor assessments
- Maintain evidence repository

### ISO 27001 Information Security
- Establish Information Security Management System (ISMS)
- Conduct risk assessments
- Implement security controls (Annex A)
- Define security policies
- Implement access management
- Protect assets
- Manage incidents
- Ensure business continuity
- Conduct internal audits
- Management review
- Continuous improvement
- Maintain documentation

### PCI-DSS (Payment Card Industry)
- Build and maintain secure network
- Protect cardholder data (encryption)
- Maintain vulnerability management
- Implement strong access controls
- Monitor and test networks regularly
- Maintain information security policy
- Conduct quarterly scans
- Perform annual penetration tests
- Implement encryption for card data
- Restrict access to cardholder data
- Track all access to network resources
- Regularly test security systems

### HIPAA (Healthcare)
- Implement physical safeguards
- Implement technical safeguards
- Implement administrative safeguards
- Ensure confidentiality of health information
- Implement access controls
- Audit controls
- Integrity controls
- Transmission security
- Document policies and procedures
- Train workforce
- Implement breach notification procedures
- Conduct risk assessments

### FedRAMP (US Government)
- Select appropriate impact level (Low, Moderate, High)
- Implement NIST 800-53 controls
- Prepare System Security Plan (SSP)
- Conduct security assessment
- Maintain continuous monitoring
- Implement Plan of Action and Milestones (POA&M)
- Use FedRAMP authorized cloud providers
- Maintain documentation
- Conduct annual assessments
- Report incidents to FedRAMP

### GDPR Compliance (European Union)
- Implement privacy by design
- Maintain data processing records
- Implement right to be forgotten
- Enable data portability
- Obtain explicit consent
- Implement data breach notification (72 hours)
- Appoint Data Protection Officer (DPO) if required
- Conduct Data Protection Impact Assessments
- Implement pseudonymization and encryption
- Maintain processing records
- Document legal basis for processing
- Implement cross-border transfer safeguards

### CCPA Compliance (California)
- Provide privacy notice
- Implement opt-out mechanism
- Honor consumer rights requests
- Implement Do Not Sell My Info option
- Maintain data inventory
- Implement data deletion procedures
- Provide data access capabilities
- Train staff on CCPA requirements
- Maintain request logs
- Implement verification procedures
- Update privacy policies
- Conduct annual compliance reviews

### Compliance Automation
- Use compliance as code tools
- Implement automated policy checks
- Use configuration management
- Implement automated evidence collection
- Use compliance monitoring tools
- Generate compliance reports automatically
- Implement continuous compliance monitoring
- Use compliance frameworks (Cloud Custodian, OPA)
- Automate control testing
- Track compliance status in real-time

### Audit Preparation
- Maintain audit trail documentation
- Organize evidence systematically
- Implement document version control
- Conduct internal audits regularly
- Prepare for external audits
- Maintain compliance calendar
- Assign compliance responsibilities
- Conduct mock audits
- Remediate findings promptly
- Update documentation continuously

### Compliance Monitoring
- Implement continuous compliance monitoring
- Track control effectiveness
- Monitor policy violations
- Generate compliance dashboards
- Alert on compliance issues
- Conduct regular compliance reviews
- Track remediation progress
- Report to management
- Maintain compliance metrics
- Conduct periodic assessments

## 69. LOGGING BEST PRACTICES (EXPANDED)

### Structured Logging
- Use JSON format for logs
- Include standard fields (timestamp, level, service, trace_id)
- Add contextual information (user_id, request_id, session_id)
- Use consistent field names across services
- Include error stack traces
- Add business context when relevant
- Use structured logging libraries (Winston, Bunyan, Logrus)
- Avoid string concatenation in logs
- Make logs machine-readable
- Enable easy parsing and filtering

### Log Levels Strategy
- **FATAL**: Application crash, immediate action required
- **ERROR**: Error conditions, needs investigation
- **WARN**: Warning messages, potential issues
- **INFO**: Important business events, milestones
- **DEBUG**: Detailed information for debugging
- **TRACE**: Very detailed tracing information
- Use appropriate levels consistently
- Configure level per environment (prod: INFO+, dev: DEBUG+)
- Document when to use each level
- Review log levels periodically

### Correlation IDs Across Services
- Generate correlation ID at entry point
- Propagate through all service calls
- Include in all log entries
- Add to HTTP headers (X-Correlation-ID)
- Use for distributed tracing
- Include in error messages
- Link logs across services
- Enable end-to-end request tracking
- Use UUID format
- Document correlation ID usage

### PII Redaction in Logs
- Identify PII fields (email, phone, SSN, credit cards)
- Implement automatic redaction
- Mask sensitive data (show last 4 digits)
- Use tokenization for identifiers
- Never log passwords or secrets
- Redact personal health information
- Implement consistent redaction patterns
- Test redaction effectiveness
- Document what gets logged
- Comply with privacy regulations

### Log Retention Policies
- **Production**: 30-90 days for quick access, longer in archives
- **Staging**: 7-30 days
- **Development**: 7 days
- Implement tiered storage (hot, warm, cold)
- Archive compliance logs for required periods
- Delete logs securely after retention
- Document retention requirements
- Consider legal and regulatory needs
- Implement automated cleanup
- Track storage costs

### Log Sampling for High Volume
- Implement adaptive sampling
- Sample based on log level (keep all ERROR, sample DEBUG)
- Use head-based sampling for traces
- Implement tail-based sampling for complete traces
- Sample based on latency thresholds
- Keep all error and exception logs
- Document sampling strategy
- Monitor sampling effectiveness
- Adjust sampling rates dynamically
- Ensure representative samples

### Audit Logging Requirements
- Log all authentication attempts
- Log authorization decisions
- Log data access and modifications
- Log configuration changes
- Log administrative actions
- Include who, what, when, where
- Make audit logs immutable
- Store separately from application logs
- Implement long-term retention
- Regular audit log reviews
- Alert on suspicious activities
- Comply with regulatory requirements

### Log Aggregation Patterns
- Use centralized logging (ELK, Splunk, CloudWatch)
- Implement log shippers (Fluentd, Logstash, Filebeat)
- Use buffering for reliability
- Implement log routing by type
- Separate security logs
- Use log enrichment
- Implement log filtering
- Optimize log transport
- Monitor log pipeline health
- Scale log infrastructure

### Performance Considerations
- Use asynchronous logging
- Implement log buffering
- Avoid logging in tight loops
- Use appropriate log levels in production
- Sample verbose logs
- Optimize log formatting
- Monitor logging overhead
- Use efficient serialization
- Implement backpressure handling
- Profile logging performance

### Log Security
- Encrypt logs in transit
- Encrypt logs at rest
- Implement access controls
- Audit log access
- Protect against log injection
- Validate log inputs
- Secure log endpoints
- Monitor for log tampering
- Implement log integrity checks
- Segregate sensitive logs

## 70. RESTful API DESIGN PRINCIPLES (DETAILED)

**Related Sections:** [24. GraphQL](#24-graphql-best-practices) | [62. gRPC](#62-grpc--protocol-buffers) | [43. API Gateway](#43-api-gateway--rate-limiting)

**Standards:** Richardson Maturity Model | Roy Fielding's REST Principles | RFC 7231 (HTTP Semantics)

### Resource Naming Conventions
- Use **nouns**, not verbs (e.g., `/users`, not `/getUsers`)
- Use **plural** for collections (e.g., `/products`, `/orders`)
- Use **hierarchical** structure for relationships (e.g., `/users/{id}/orders`)
- Use **lowercase** and **hyphens** for URLs (e.g., `/user-profiles`)
- Avoid deep nesting (max 2-3 levels: `/resources/{id}/sub-resources`)
- Use **query parameters** for filtering, sorting, pagination
- Keep URLs **intuitive** and **predictable**

### HTTP Methods Semantics
- **GET**: Retrieve resource(s) - idempotent, safe, cacheable
  - `GET /users` - Get list of users
  - `GET /users/{id}` - Get specific user
  - Return 200 OK or 404 Not Found
- **POST**: Create new resource - not idempotent
  - `POST /users` - Create new user
  - Return 201 Created with Location header
  - Include created resource in response body
- **PUT**: Replace entire resource - idempotent
  - `PUT /users/{id}` - Replace user completely
  - Return 200 OK or 204 No Content
  - Create resource if not exists (optional)
- **PATCH**: Partial update - may or may not be idempotent
  - `PATCH /users/{id}` - Update specific fields
  - Return 200 OK with updated resource
  - Use JSON Patch (RFC 6902) or JSON Merge Patch (RFC 7386)
- **DELETE**: Remove resource - idempotent
  - `DELETE /users/{id}` - Delete user
  - Return 204 No Content or 200 OK
  - Consider soft delete for audit trails

### HTTP Status Codes (Proper Usage)
**Success Codes (2xx):**
- 200 OK - Successful GET, PUT, PATCH, or DELETE
- 201 Created - Successful POST (include Location header)
- 202 Accepted - Request accepted for async processing
- 204 No Content - Successful request with no response body

**Redirection Codes (3xx):**
- 301 Moved Permanently - Resource permanently moved
- 302 Found - Temporary redirect
- 304 Not Modified - Use cached version

**Client Error Codes (4xx):**
- 400 Bad Request - Invalid syntax or validation failed
- 401 Unauthorized - Authentication required
- 403 Forbidden - Authenticated but not authorized
- 404 Not Found - Resource doesn't exist
- 405 Method Not Allowed - HTTP method not supported
- 409 Conflict - Resource conflict (e.g., duplicate)
- 422 Unprocessable Entity - Validation errors
- 429 Too Many Requests - Rate limit exceeded

**Server Error Codes (5xx):**
- 500 Internal Server Error - Generic server error
- 502 Bad Gateway - Invalid response from upstream
- 503 Service Unavailable - Temporary unavailability
- 504 Gateway Timeout - Upstream timeout

### Response Format Consistency
```json
// Success Response
{
  "data": { ... },
  "meta": {
    "timestamp": "2025-10-19T10:30:00Z",
    "version": "1.0"
  }
}

// Error Response  
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid email format",
    "details": [
      {
        "field": "email",
        "issue": "Must be valid email address"
      }
    ]
  },
  "meta": {
    "timestamp": "2025-10-19T10:30:00Z",
    "request_id": "req-12345"
  }
}

// Paginated Response
{
  "data": [...],
  "pagination": {
    "page": 1,
    "per_page": 20,
    "total": 150,
    "total_pages": 8
  },
  "links": {
    "self": "/users?page=1",
    "next": "/users?page=2",
    "last": "/users?page=8"
  }
}
```

### Pagination Strategies
- **Offset-based**: `?page=2&limit=20` or `?offset=20&limit=20`
  - Simple to implement
  - Works well for small datasets
  - Issues with data consistency during pagination
- **Cursor-based**: `?cursor=eyJpZCI6MTAwfQ&limit=20`
  - Better performance for large datasets
  - Consistent results even with data changes
  - Recommended for real-time data
- **Use Link headers** (RFC 5988) for navigation
- Include total count when appropriate
- Document pagination limits and defaults
- Implement maximum page size limits

### Filtering, Sorting & Searching
```
Filtering:
GET /products?category=electronics&price_min=100&price_max=500
GET /users?status=active&role=admin

Sorting:
GET /products?sort=price_asc
GET /users?sort=-created_at (descending)

Searching:
GET /products?q=laptop&search_fields=name,description
GET /users?search=john.doe@example.com

Combined:
GET /products?category=electronics&price_max=500&sort=price_asc&page=2&limit=20
```

### Versioning Strategies
1. **URL Versioning** (Most common)
   - `/api/v1/users`
   - `/api/v2/users`
   - Simple, clear, easy to route
2. **Header Versioning**
   - `Accept: application/vnd.company.v1+json`
   - Cleaner URLs
   - More complex routing
3. **Query Parameter**
   - `/api/users?version=1`
   - Not recommended (violates REST principles)

### HATEOAS (Hypermedia as the Engine of Application State)
```json
{
  "data": {
    "id": 123,
    "name": "John Doe",
    "email": "john@example.com"
  },
  "links": {
    "self": "/users/123",
    "orders": "/users/123/orders",
    "edit": "/users/123",
    "delete": "/users/123"
  }
}
```

### Content Negotiation
- Support multiple formats (JSON, XML, etc.)
- Use Accept header: `Accept: application/json`
- Use Content-Type header: `Content-Type: application/json`
- Default to JSON if not specified
- Return 406 Not Acceptable for unsupported formats

### Caching & Performance
- Use ETags for cache validation
- Implement Cache-Control headers
- Use conditional requests (If-None-Match, If-Modified-Since)
- Return 304 Not Modified for unchanged resources
- Implement server-side caching where appropriate
- Use CDN for static responses
- Implement response compression (gzip, brotli)

### Security Headers
```
Content-Security-Policy: default-src 'self'
X-Frame-Options: DENY
X-Content-Type-Options: nosniff
Strict-Transport-Security: max-age=31536000; includeSubDomains
X-XSS-Protection: 1; mode=block
Referrer-Policy: strict-origin-when-cross-origin
```

### Rate Limiting Headers
```
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 950
X-RateLimit-Reset: 1634654400
Retry-After: 3600
```

### API Documentation Standards
- Use OpenAPI 3.x specification
- Document all endpoints, parameters, responses
- Include request/response examples
- Document authentication requirements
- Include error response examples
- Provide code examples in multiple languages
- Keep documentation up-to-date with code
- Use interactive documentation (Swagger UI, ReDoc)

## 71. QUICK REFERENCE GUIDE

### Code Quality Checklist
- [ ] Code follows SOLID principles
- [ ] Functions are small and focused (<50 lines)
- [ ] Meaningful variable and function names
- [ ] No magic numbers or strings (use constants)
- [ ] No code duplication (DRY principle)
- [ ] Proper error handling implemented
- [ ] Code is properly commented (WHY, not WHAT)
- [ ] Code is formatted consistently

### Security Checklist
- [ ] Input validation on all user inputs
- [ ] Parameterized queries (no SQL injection)
- [ ] Authentication and authorization implemented
- [ ] Sensitive data encrypted (at rest and in transit)
- [ ] HTTPS enforced everywhere
- [ ] Security headers configured
- [ ] CSRF protection implemented
- [ ] XSS prevention in place
- [ ] Rate limiting configured
- [ ] No secrets in code or version control

### Testing Checklist
- [ ] Unit tests for critical functionality (>80% coverage)
- [ ] Integration tests for APIs
- [ ] E2E tests for critical user flows
- [ ] Edge cases and error scenarios tested
- [ ] Tests are independent and isolated
- [ ] Mock external dependencies
- [ ] Tests run in CI/CD pipeline

### Deployment Checklist
- [ ] All tests passing
- [ ] Code reviewed and approved
- [ ] Security vulnerabilities resolved
- [ ] Database migrations tested
- [ ] Feature flags configured
- [ ] Monitoring dashboards created
- [ ] Alerts configured
- [ ] Runbooks updated
- [ ] Rollback plan documented
- [ ] Deployment scheduled (not Friday!)

### Performance Checklist
- [ ] Database queries optimized (indexes, no N+1)
- [ ] Caching implemented where appropriate
- [ ] Images and assets optimized
- [ ] Lazy loading for heavy components
- [ ] Bundle size minimized
- [ ] API calls minimized
- [ ] No memory leaks
- [ ] Performance profiled and baselined

### Production Operations Checklist
- [ ] Health check endpoints implemented
- [ ] Monitoring configured and tested
- [ ] Logging centralized and structured
- [ ] Alerts set with proper thresholds
- [ ] Backups automated and tested
- [ ] Disaster recovery plan documented
- [ ] On-call rotation assigned
- [ ] Incident response procedures ready
- [ ] Capacity planning completed
- [ ] Cost monitoring configured

### Common Commands Quick Reference

**Git Commands:**
```bash
git commit -m "feat(auth): add OAuth2 support"
git commit -m "fix(api): resolve rate limiting issue"
git commit -m "docs: update API documentation"
git rebase -i HEAD~3  # Interactive rebase
git cherry-pick <commit-hash>  # Cherry-pick specific commit
```

**Docker Commands:**
```bash
docker build -t app:1.0.0 .
docker run -p 3000:3000 app:1.0.0
docker-compose up -d
docker ps  # List running containers
docker logs -f <container-id>  # Follow logs
```

**Kubernetes Commands:**
```bash
kubectl get pods
kubectl describe pod <pod-name>
kubectl logs -f <pod-name>
kubectl apply -f deployment.yaml
kubectl rollout status deployment/<deployment-name>
kubectl rollout undo deployment/<deployment-name>  # Rollback
```

**Database Migrations:**
```bash
# Flyway
flyway migrate
flyway info
flyway validate

# Liquibase  
liquibase update
liquibase rollback <tag>

# Alembic (Python)
alembic upgrade head
alembic downgrade -1
```

### Performance Metrics Quick Reference

**Response Time Targets:**
- p50 (median): < 100ms
- p95: < 300ms
- p99: < 500ms
- p99.9: < 1000ms

**Availability Targets:**
- 99.9% (three nines): ~43 minutes downtime/month
- 99.95%: ~21 minutes downtime/month
- 99.99% (four nines): ~4 minutes downtime/month
- 99.999% (five nines): ~26 seconds downtime/month

**Code Coverage Targets:**
- Critical paths: 90%+
- Overall: 80%+
- Minimum acceptable: 70%

**DORA Metrics Targets:**
- Deployment Frequency: Multiple per day (Elite)
- Lead Time: < 1 hour (Elite)
- MTTR: < 1 hour (Elite)
- Change Failure Rate: < 15% (Elite)

### Security Standards Quick Reference

**Password Requirements:**
- Minimum 12 characters
- Mix of uppercase, lowercase, numbers, symbols
- No common passwords (check against known lists)
- Implement password strength meter
- No password hints or recovery questions

**Token Expiration:**
- Access tokens: 15-60 minutes
- Refresh tokens: 7-30 days
- API keys: Rotate every 90 days
- Session tokens: 30 minutes idle, 8 hours absolute

**Encryption Standards:**
- At rest: AES-256
- In transit: TLS 1.2+ (prefer TLS 1.3)
- Passwords: bcrypt (cost 12+), Argon2id, or PBKDF2
- RSA: 2048+ bits (prefer 4096)

## 72. VERSION CHANGELOG

### Version 1.0 (2025-10-19) - Initial Release

**Complete Enterprise-Grade Coding Standards**

**Sections Included:**
- Table of Contents with 8 logical parts (I-VIII)
- Production Operations & Maintenance (Section 15)
- OWASP Top 10 detailed coverage in Security
- CI/CD Pipeline Best Practices (Section 59)
- SRE Practices with SLI/SLO/SLA (Section 60)
- Event-Driven Architecture & Event Sourcing (Section 61)
- Infrastructure as Code Detailed (Section 62)
- gRPC & Protocol Buffers (Section 63)
- API Contract Testing & Schema Management (Section 64)
- Service Mesh Patterns (Section 65)
- Webhooks Best Practices (Section 66)
- Green Computing & Sustainability (Section 67)
- Compliance Frameworks Detailed (Section 68)
- Logging Best Practices Expanded (Section 69)
- RESTful API Design Principles (Section 70)
- Quick Reference Guide (Section 71)
- Version Changelog (Section 72)

**Key Features:**
- Merged Internationalization sections for clarity
- Cross-references between related sections throughout
- International standards references (ISO, IEEE, W3C, OWASP, NIST, CIS)
- Comprehensive testing coverage (unit, integration, E2E, contract, mutation, visual regression)
- Complete Build & Deployment with 4 deployment strategies
- Critical ALWAYS/NEVER rules in Special Instructions
- Database optimization (connection pooling, sharding, read/write splitting)
- OWASP Top 10 (2021) detailed implementation guide
- Production Operations with 14-point deployment checklist
- Deployment strategies (Blue-Green, Canary, Rolling, Feature Toggle)
- Database migration best practices with zero-downtime strategies

**Complete Coverage:**
- 72 comprehensive sections
- 4,800+ lines of best practices
- 15+ programming languages (Flutter, JS/TS, Python, Java, C#, Go, Rust, PHP, Ruby, Kotlin, Swift, SQL, HTML, CSS)
- 6+ NoSQL databases (MongoDB, Redis, DynamoDB, Cassandra, Elasticsearch, Firebase)
- 3 cloud platforms (AWS, Azure, GCP)
- 4 frontend frameworks (React, Vue, Angular, Svelte)
- Complete Firebase integration guide
- Enterprise-grade security and compliance (9 frameworks)
- Modern DevOps and SRE practices
- Production-ready operations guide

**Standards Compliance:**
- ISO/IEC 25010 (Software Quality)
- IEEE 730 (Software Quality Assurance)  
- ISO 27001 (Information Security)
- OWASP Top 10 (Web Security)
- W3C Standards (HTML, CSS, Accessibility)
- WCAG 2.1 Level AA (Accessibility)
- SOC 2 Type II, HIPAA, PCI-DSS, GDPR, CCPA, FedRAMP
- NIST Cybersecurity Framework
- CIS Benchmarks (Security Hardening)

---

## USAGE GUIDELINES

### How to Use This Document

1. **For New Projects:**
   - Review relevant sections based on tech stack
   - Implement foundational practices first (Part I)
   - Set up CI/CD and monitoring early (Part VI)
   - Reference specific sections as needed

2. **For Code Reviews:**
   - Use relevant sections as review checklist
   - Reference section numbers in review comments
   - Focus on security, testing, and performance sections

3. **For Team Onboarding:**
   - Share entire document as reference
   - Start with Part I (Foundations)
   - Deep dive into technology-specific sections
   - Use Quick Reference Guide for daily work

4. **For Production Deployment:**
   - Follow Section 15 (Production Operations)
   - Review Section 59 (SRE Practices)
   - Check Section 47 (Disaster Recovery)
   - Validate against deployment checklists

5. **For Architecture Decisions:**
   - Review Part II (Data & Backend)
   - Study Part VI (Infrastructure & Operations)
   - Consider Part VII (Advanced Topics)
   - Document decisions using ADRs (Section 7)

### Customization for Your Project

This document provides comprehensive guidelines. Adapt based on:
- **Project size**: Startups may not need all sections initially
- **Tech stack**: Focus on relevant language/framework sections
- **Compliance needs**: Implement required compliance frameworks
- **Team size**: Scale practices appropriately
- **Industry**: Prioritize industry-specific requirements

### Contributing to This Document

- Suggest improvements via pull requests
- Keep standards current with industry changes
- Add examples and real-world scenarios
- Update references to latest specifications
- Maintain professional tone throughout

---

**Last Updated:** 2025-10-19  
**Version:** 1.0  
**Total Sections:** 72  
**Total Lines:** 4,800+  
**Maintained by:** Development Team

---

These rules should be applied to all coding projects to ensure high quality, maintainable, secure, and performant code. Adherence to these standards will result in professional-grade software that follows industry best practices.

**Standards Compliance:**
[x] ISO/IEC 25010 (Software Quality)  
[x] IEEE 730 (Software Quality Assurance)  
[x] ISO 27001 (Information Security)  
[x] OWASP Top 10 (Web Security)  
[x] W3C Standards (HTML, CSS, Accessibility)  
[x] WCAG 2.1 Level AA (Accessibility)  
[x] GDPR, CCPA, HIPAA, PCI-DSS (Compliance)  
[x] NIST Cybersecurity Framework  
[x] CIS Benchmarks (Security Hardening)